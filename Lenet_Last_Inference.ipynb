{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRdUpVPo0rCU9ah3ZzoE+F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatisepah/samples/blob/main/Lenet_Last_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22wlQIiEl0n6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "prediction=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKIpp6RbIOnA"
      },
      "outputs": [],
      "source": [
        "class Convolution2D:\n",
        "\n",
        "\n",
        "    def __init__(self, inputs_channel, num_filters, kernel_size, padding, stride):\n",
        "        # weight size: (F, C, K, K)\n",
        "        # bias size: (F) \n",
        "        self.F = num_filters\n",
        "        self.K = kernel_size\n",
        "        self.C = inputs_channel\n",
        "        \n",
        "        # print(\"FInConv=\",self.F)\n",
        "        # print(\"KInConv=\",self.K)\n",
        "        # print(\"CInConv=\",self.C)\n",
        "\n",
        "        print(\"In Conv's Init\")\n",
        "\n",
        "\n",
        "        self.weights = np.zeros((self.F, self.C, self.K, self.K))\n",
        "        self.bias = np.zeros((self.F, 1))\n",
        "        for i in range(0,self.F):\n",
        "            self.weights[i,:,:,:] = np.random.normal(loc=0, scale=np.sqrt(1./(self.C*self.K*self.K)), size=(self.C, self.K, self.K))\n",
        "\n",
        "        if prediction == True:\n",
        "          for f in range(self.F):\n",
        "            for c in range(self.C):\n",
        "              for h in range(self.K):\n",
        "                for w in range(self.K):\n",
        "                  self.weights[f,c,h,w]=int(self.weights[f,c,h,w]*31)\n",
        "\n",
        "          self.weights=self.weights.astype(int)\n",
        "\n",
        "        # print(\"weightsShapeConvLayer=\",self.weights.shape)\n",
        "        print(\"weightsConvLayer=\",self.weights)\n",
        "\n",
        "        self.p = padding\n",
        "        self.s = stride\n",
        "\n",
        "        # print(\"F(num_filters)ConvLayer=\",self.F)\n",
        "        # print(\"K(kernel_size)ConvLayer=\",self.K)\n",
        "        # print(\"C(inputs_channel)ConvLayer=\",self.C)\n",
        "\n",
        "    def zero_padding(self, inputs, size):\n",
        "        w, h = inputs.shape[0], inputs.shape[1]\n",
        "        new_w = 2 * size + w\n",
        "        new_h = 2 * size + h\n",
        "        out = np.zeros((new_w, new_h))\n",
        "        out[size:w+size, size:h+size] = inputs\n",
        "\n",
        "        \n",
        "\n",
        "        print(\"outShapezeropadding=\",out.shape)\n",
        "        return out\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # input size: (C, W, H)\n",
        "        # output size: (N, F ,WW, HH)\n",
        "        print(\"inputOfConvLayer=\",inputs)\n",
        "        # print(\"inputShapeOfConvLayer=\",inputs.shape)\n",
        "\n",
        "        print(\"In Conv's forward\")\n",
        "\n",
        "\n",
        "        C = inputs.shape[0]\n",
        "        # print(\"C-inputs.shape[0]=\",C)\n",
        "\n",
        "        W = inputs.shape[1]+2*self.p\n",
        "        # print(\"W-inputs.shape[1]=\",W)\n",
        "\n",
        "        H = inputs.shape[2]+2*self.p\n",
        "        # print(\"H-inputs.shape[2]=\",H)\n",
        "\n",
        "        self.inputs = np.zeros((C, W, H))\n",
        "        # print(\"self.inputsConv=\",self.inputs)\n",
        "\n",
        "        for c in range(inputs.shape[0]):\n",
        "            self.inputs[c,:,:] = self.zero_padding(inputs[c,:,:], self.p)\n",
        "        # print(\"OutZero_padding=\",self.inputs)\n",
        "\n",
        "        #############  \n",
        "        WW =int((W - self.K)/self.s + 1)\n",
        "        # print(\"WW=\",WW)\n",
        "        ##########\n",
        "        HH = int((H - self.K)/self.s + 1)\n",
        "        # print(\"HH=\",HH)\n",
        "\n",
        "        feature_maps = np.zeros((self.F, WW, HH))\n",
        "        # print(\"feature_mapsOfConvLayerzero=\",feature_maps)\n",
        "\n",
        "        for f in range(self.F):\n",
        "            for w in range(0, WW, self.s):\n",
        "                for h in range(0, HH, self.s):\n",
        "                    # print(\"SelectInputh=\",self.inputs[:,w:w+self.K,h:h+self.K])\n",
        "                    sel=self.inputs[:,w:w+self.K,h:h+self.K]\n",
        "                    # print(\"SelectInputShape=\",sel.shape)\n",
        "                    Weights=self.weights[f,:,:,:]\n",
        "                    # print(\"WeightShape=\",Weights.shape)\n",
        "                    feature_maps[f,w,h]=np.sum(self.inputs[:,w:w+self.K,h:h+self.K]*self.weights[f,:,:,:])+self.bias[f]\n",
        "                    # print(\"feature_mapsOfConvLayer=\",feature_maps)\n",
        "        # print(\"Lastfeature_mapsOfConvLayer=\",feature_maps.shape)\n",
        "        # print(\"conv's forward is done\")\n",
        "\n",
        "        return feature_maps\n",
        "\n",
        "    def forwardStochastic(self, inputs):#Stochastic\n",
        "        # input size: (C, W, H)\n",
        "        # output size: (N, F ,WW, HH)\n",
        "        print(\"inputOfConvLayer=\",inputs)\n",
        "        # print(\"inputShapeOfConvLayer=\",inputs.shape)\n",
        "\n",
        "        print(\"In Conv's forwardStocahstic\")\n",
        "\n",
        "        C = inputs.shape[0]\n",
        "        W = inputs.shape[1]+2*self.p\n",
        "        H = inputs.shape[2]+2*self.p\n",
        "\n",
        "\n",
        "        self.weights=self.weights.astype(int)\n",
        "\n",
        "\n",
        "        XBit=5\n",
        "        QBit=2\n",
        "        QTZRange=2**QBit\n",
        "        sign=1\n",
        "        XYInputBuf=inputs.shape\n",
        "        # print(\"XYInputBuf\",inputs.shape)\n",
        "        XInputBuf= XYInputBuf[1]+2*self.p\n",
        "        YInputBuf= XYInputBuf[2]+2*self.p\n",
        "        # print(\"XInputBuf\",XInputBuf)\n",
        "        # print(\"YInputBuf\",YInputBuf)\n",
        "\n",
        "        #find dimention of weight buffer\n",
        "        XYWeightBuf=self.weights.shape\n",
        "        XWBuf= XYWeightBuf[2]\n",
        "        YWBuf= XYWeightBuf[3]\n",
        "        lenWeight=len(self.weights)\n",
        "\n",
        "        ArrayMulReshape=np.array([])\n",
        "        ListKeyWeight=[]\n",
        "        DicWeight={}\n",
        "        #/////////////////////////////////////////////////////////////////////////////////////////////////////\n",
        "        \n",
        "\n",
        "        def DetectTheFirstValueOfRange(WeightBuffer):\n",
        "        \n",
        "        \t#reshape WeightSortArray to 1-D\n",
        "        \tWeightBuffer1D=WeightBuffer.reshape(-1)\n",
        "        \tprint(\"WeightBuffer1D=\",WeightBuffer1D)\n",
        "        \tXWeightBuf1D=WeightBuffer1D.shape[0]\n",
        "        \n",
        "        \n",
        "            #changing value of weightBuffer with the first value of each range\n",
        "        \ti=0\n",
        "        \twhile i<XWeightBuf1D:\n",
        "        \t\tif WeightBuffer1D[i]<0:\n",
        "        \t\t\tfor x in range(QTZRange):\n",
        "        \t\t\t\tNfirst=((-(x+1)/QTZRange)*(2**XBit))-1\n",
        "        \t\t\t\tNlast=((-(x/QTZRange)*(2**XBit))-1)\n",
        "        \n",
        "        \t\t\t\tif (WeightBuffer1D[i]>Nfirst) &  (WeightBuffer1D[i]<=Nlast):\n",
        "        \t\t\t\t\t#the first value of each range\n",
        "        \t\t\t\t\tWeightBuffer1D[i]=Nfirst+1\n",
        "        \t\t\t\t\tbreak\n",
        "        \t\telse:\n",
        "        \t\t\tfor x in range(QTZRange):\n",
        "        \t\t\t\tPfirst=((x/QTZRange)*(2**XBit))\n",
        "        \t\t\t\tPlast=((x+1)/QTZRange)*(2**XBit)\n",
        "        \n",
        "        \t\t\t\tif (WeightBuffer1D[i]>=Pfirst) &  (WeightBuffer1D[i]<Plast):\n",
        "        \t\t\t\t\t#the first value of each range\n",
        "        \t\t\t\t\tWeightBuffer1D[i]=Pfirst\n",
        "        \t\t\t\t\tbreak\n",
        "        \t\ti+=1\n",
        "        \tprint(\"WB-DetectTheFirstValueOfRange=\",WeightBuffer1D)\n",
        "        \treturn WeightBuffer1D\n",
        "        \n",
        "        #/////////////////////////////////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "\n",
        "        def UpDownCounter(Enable,x,IncDec):\n",
        "          IntX=int(x)\n",
        "          Enable=int(Enable)\n",
        "          \n",
        "          if Enable != 0:\n",
        "            if IntX == 1:\n",
        "              if IncDec == 1:\n",
        "                IntX=1\n",
        "              else:\n",
        "                IntX=-1\n",
        "            else:\n",
        "              IntX=0\n",
        "          else:\n",
        "            IntX=0\n",
        "          return IntX\n",
        "        #/////////////////////////////////////////////////////////////////////////////////////////////////////\n",
        "        def DownCounter(x):\n",
        "          x-=1\n",
        "          return x\n",
        "        #/////////////////////////////////////////////////////////////////////////////////////////////////////\n",
        "        \n",
        "        def BISC(In):\n",
        "          # print(\"InBISC\",In)\n",
        "          # print(\"TypeInBISC\",type(In))\n",
        "          LenSc= 2 ** XBit\n",
        "          \n",
        "          sc=np.array([])\n",
        "          for x in range(LenSc):\n",
        "            sc=np.append(sc,[0])\n",
        "            \n",
        "          for x in range(XBit):\n",
        "            i=(2 ** x)-1\n",
        "            while i<LenSc:\n",
        "              sc[i] = In[x]\n",
        "              i+= 2 ** (x+1)\n",
        "              \n",
        "          sc = np.flip(sc)\n",
        "          return sc\n",
        "          \n",
        "        #/////////////////////////////////////////////////////////////////////////////////////////////////////\n",
        "        def DecimalToBinary(num,XBit):\n",
        "          i = 0\n",
        "          bnum = []\n",
        "          Binary=''\n",
        "          while num!=0:\n",
        "            rem = num%2\n",
        "            bnum.insert(i, rem)\n",
        "            i = i+1\n",
        "            num = int(num/2)\n",
        "          i = i-1\n",
        "          while i>=0:\n",
        "            Binary=Binary+str(bnum[i])\n",
        "            i = i-1\n",
        "          \n",
        "          while len(Binary)<XBit:\n",
        "            Binary='0'+Binary\n",
        "          # print(\"Binary:\",Binary)\n",
        "          \n",
        "          return Binary\n",
        "        #/////////////////////////////////////////////////////////////////////////////////////////////////////\n",
        "        def GetDefferentialWArray(w):\n",
        "          DifferentialWArray=np.array([])\n",
        "          \n",
        "          #sort weight 1-D\n",
        "          WeightSortArray1D=np.sort(w)\n",
        "          # print(\"WeightSortArray1D=\",WeightSortArray1D)\n",
        "          \n",
        "          #create sorted weight array based on Differential of weights\n",
        "          \n",
        "          DifferentialWArray=np.append(DifferentialWArray,WeightSortArray1D[0])\n",
        "          for x in range((XWBuf*YWBuf)-1):\n",
        "            Differential=WeightSortArray1D[x+1]-WeightSortArray1D[x]\n",
        "            DifferentialWArray=np.append(DifferentialWArray,Differential)\n",
        "          # print(\"DifferentialWArray=\",DifferentialWArray)\n",
        "          \n",
        "          return DifferentialWArray\n",
        "          \n",
        "        #/////////////////////////////////////////////////////////////////////////////////////////////////////\n",
        "        \n",
        "        def SortDicIndexWeight(w):\n",
        "          w=np.reshape(w,(XWBuf,YWBuf))\n",
        "          # print(\"WInSortDicShape=\",w.shape)\n",
        "          # print(\"XWBuf=\",XWBuf)\n",
        "          # print(\"YWBuf=\",YWBuf)\n",
        "          for x in range(XWBuf):\n",
        "            for y in range(YWBuf):\n",
        "              str=x,y\n",
        "              # print(\"str\",str)\n",
        "              # print(\"w[x,y]\",w[x,y])\n",
        "              DicWeight[str]=w[x,y]\n",
        "              \n",
        "          #sort dic of weight baes on value:dic(key,value)\n",
        "          DicWSort=dict(sorted(DicWeight.items(), key=lambda item: item[1]))\n",
        "          # print(\"DicWSort=\",DicWSort)\n",
        "          \n",
        "          for x in range(XWBuf*YWBuf):\n",
        "            ListKeyWeight.append(list(DicWSort.keys())[x])\n",
        "            \n",
        "          # print(\"ListKeyWeight=\",ListKeyWeight)\n",
        "            \n",
        "        #/////////////////////////////////////////////////////////////////////////////////////////////////////\n",
        "        \n",
        "        #function for doing the functional of PE in skippy based on BISC & Uo/Down counter & Down counter\n",
        "        def Mul(InputBuffer,WeightBuffer):\n",
        "          OutputArray=np.array([])\n",
        "          # print(\"WeightBufferBeforReshape=\",WeightBuffer)\n",
        "          WeightBuffer=np.reshape(WeightBuffer,(XWBuf,YWBuf))\n",
        "          # print(\"WeightBufferAfterReshape=\",WeightBuffer)\n",
        "\n",
        "          WeightBuffer1D=DetectTheFirstValueOfRange(WeightBuffer)\n",
        "\n",
        "          # print(\"InputBuffershapeBefor=\",InputBuffer.shape)\n",
        "          InputBuffer=np.reshape(InputBuffer,(XInputBuf,YInputBuf))\n",
        "          # print(\"InputBuffershapeAfter=\",InputBuffer.shape)\n",
        "\n",
        "          #reshape WeightSortArray to 1-D\n",
        "          WeightBuffer1D=WeightBuffer.reshape(-1)\n",
        "          # print(\"WeightBuffer1D=\",WeightBuffer1D)\n",
        "          DifferentialW=GetDefferentialWArray(WeightBuffer1D)\n",
        "          \n",
        "          ClockNum=0\n",
        "          for i in range(len(DifferentialW)):\n",
        "            ClockNum=ClockNum+abs(DifferentialW[i])\n",
        "            \n",
        "          ClockNum*=((XInputBuf-XWBuf)+1)*((YInputBuf-YWBuf)+1)\n",
        "          # print(\"ClockNum=\",ClockNum)\n",
        "          \n",
        "          SortDicIndexWeight(WeightBuffer)\n",
        "          \n",
        "          for x in range((XInputBuf-XWBuf)+1):\n",
        "            for y in range((YInputBuf-YWBuf)+1):\n",
        "              \n",
        "              SelectIn=InputBuffer[x:XWBuf+x ,y:YWBuf+y]\n",
        "              # print(\"SelectInShape=\",SelectIn.shape)\n",
        "              # print(\"SelectIn=\",SelectIn)\n",
        "              \n",
        "              SumOut=0\n",
        "              \n",
        "              for a in range(XWBuf):\n",
        "                for b in range(YWBuf):\n",
        "                  LenDiffW= len(DifferentialW)\n",
        "                  SumList=[]\n",
        "                  \n",
        "                  for s in range(LenDiffW):\n",
        "                    SumList.append(0)\n",
        "\n",
        "                  X=SelectIn[a,b]\n",
        "                  XBinary=DecimalToBinary(X,XBit)\n",
        "                    \n",
        "                  SC=BISC(XBinary)\n",
        "                  andisY=0\n",
        "                    \n",
        "                  # print(\"LenDiffW\",LenDiffW)\n",
        "                  for z in range(LenDiffW):\n",
        "                    andisSC=0\n",
        "                    # print(\"z\",z)\n",
        "                      \n",
        "                    ValWInDiff=DifferentialW[z]\n",
        "                    #print(type(ValWInDiff))\n",
        "                      \n",
        "                    if ValWInDiff == 0:\n",
        "                      if z==0:\n",
        "                        SumList[andisY]=0\n",
        "                      else:\n",
        "                        SumList[andisY]=SumList[andisY-1]\n",
        "                      andisY+=1\n",
        "                      continue\t\t\t\t\t\t\n",
        "                        \n",
        "                    #instantiating the variable of sign holder \n",
        "                    #if sign=0, number is negative & sign=1, number is positive\n",
        "                      \n",
        "                    if ValWInDiff<0:\n",
        "                      sign=0\n",
        "                      ValWInDiff=abs(ValWInDiff)\n",
        "                    else:\n",
        "                      sign=1\n",
        "                        \n",
        "                    sum=0\n",
        "                    while ValWInDiff>0:\n",
        "                        \n",
        "                      OutUDCounter=UpDownCounter(ValWInDiff,SC[(len(SC)-1)-andisSC],sign)\n",
        "                      andisSC+=1\n",
        "                      ValWInDiff=DownCounter(ValWInDiff)\n",
        "                      sum=sum+OutUDCounter\n",
        "                        \n",
        "                        \n",
        "                    if z==0:\n",
        "                      SumList[andisY]=sum\n",
        "                    else:\n",
        "                      SumList[andisY]=SumList[andisY-1]+sum\n",
        "                    andisY+=1\n",
        "\n",
        "                  # print(\"SumList=\",SumList)\n",
        "                    \n",
        "                  Index=ListKeyWeight.index((a,b))\n",
        "                  val=SumList[Index]\n",
        "                  # print(\"ValIndex=\",val)\t\n",
        "                  SumOut=SumOut+val\n",
        "                  if SumOut >= (2**XBit):\n",
        "                    SumOut=2**XBit\n",
        "                    break\n",
        "                  if SumOut <= -(2**XBit):\n",
        "                    SumOut=-(2**XBit)\n",
        "                    break\n",
        "              # print(\"SumOut=\",SumOut)\n",
        "                \n",
        "              #two lines for compute the last result baesd on stochastic(divide on 2**XBit)\n",
        "              SumOut=SumOut/2**XBit\n",
        "              # print(\"SumOut=\",SumOut)\t\n",
        "                \n",
        "              OutputArray=np.append(OutputArray,SumOut)\n",
        "                \n",
        "          # print(\"OutputArray=\",OutputArray)\n",
        "          NewOutputArray=OutputArray.reshape((XInputBuf-XWBuf)+1,(YInputBuf-YWBuf)+1)\n",
        "          # print(\"NewOutputArray=\",NewOutputArray)\n",
        "          # print(\"NewOutputArrayShape=\",NewOutputArray.shape)\n",
        "          return NewOutputArray\n",
        "\n",
        "\n",
        "#////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "        self.inputs = np.zeros((C, W, H))\n",
        "        # print(\"self.inputsConv=\",self.inputs)\n",
        "\n",
        "        for c in range(inputs.shape[0]):\n",
        "            self.inputs[c,:,:] = self.zero_padding(inputs[c,:,:], self.p)\n",
        "        # print(\"OutshapeZero_padding=\",self.inputs.shape)\n",
        "\n",
        "        for c in range(C):\n",
        "          for w in range(W):\n",
        "            for h in range(H):\n",
        "              self.inputs[c,w,h]= int(self.inputs[c,w,h]*31)\n",
        "\n",
        "        self.inputs= self.inputs.astype(int)\n",
        "\n",
        "        print(\"inputOfConvLayer=\",self.inputs)\n",
        "        # print(\"inputShapeOfConvLayer=\",self.inputs.shape)\n",
        "\n",
        "        #############  \n",
        "        WW =int((W - self.K)/self.s + 1)\n",
        "        # print(\"WW=\",WW)\n",
        "        ##########\n",
        "        HH = int((H - self.K)/self.s + 1)\n",
        "        # print(\"HH=\",HH)\n",
        "\n",
        "\n",
        "\n",
        "        feature_maps = np.zeros((self.F, WW, HH))\n",
        "        # print(\"feature_mapsShapeOfConvLayerzero=\",feature_maps.shape)\n",
        "\n",
        "        # print(\"FInConvInForward=\",self.F)\n",
        "\n",
        "\n",
        "        for f in range(self.F):\n",
        "          SumArrayF = np.zeros((WW, HH))\n",
        "          for c in range(self.C):\n",
        "            # print(\"f=\",f)\n",
        "            # print(\"c=\",c)\n",
        "\n",
        "            # print(\"inputssShape=\",self.inputs[c,:,:].shape)\n",
        "            # print(\"inputs=\",self.inputs[c,:,:])\n",
        "            # weights=np.reshape(self.weights[f,:,:,:],(XWBuf,YWBuf))\n",
        "            # print(\"weights=\",self.weights[f,c,:,:])\n",
        "            # print(\"OUTMulShape\",np.array(Mul(self.inputs[c,:,:],self.weights[f,c,:,:])).shape)\n",
        "            SumArrayF[:,:]=np.array(SumArrayF)+np.array(Mul(self.inputs[c,:,:],self.weights[f,c,:,:]))\n",
        "            # print(\"SumArrayFShape=\",SumArrayF[:,:].shape)\n",
        "            # print(\"SumArrayF=\",SumArrayF[:,:])\n",
        "\n",
        "\n",
        "          # print(\"SumArrayFShapeOUT=\",SumArrayF.shape)\n",
        "          # print(\"SumArrayF=\",SumArrayF)\n",
        "          \n",
        "          feature_maps[f,:,:]=SumArrayF[:,:]+self.bias[f]\n",
        "            \n",
        "        # print(\"feature_mapsShapeOfConvLayer=\",feature_maps.shape)\n",
        "        \n",
        "\n",
        "        return feature_maps\n",
        "    \n",
        "\n",
        "    def backward(self, output_error, learning_rate):\n",
        "        # print(\"output_errorInBackConvShape=\",output_error.shape)\n",
        "\n",
        "        C, W, H = self.inputs.shape\n",
        "        # print(\"inputsconvvvv.shape=\",self.inputs.shape)\n",
        "\n",
        "        WW =int((W - self.K)/self.s + 1)\n",
        "        # print(\"WW=\",WW)\n",
        "        ##########\n",
        "        HH = int((H - self.K)/self.s + 1)\n",
        "        # print(\"HH=\",HH)\n",
        "\n",
        "        self.weights=self.weights.astype(float)\n",
        "\n",
        "\n",
        "        dx = np.zeros(self.inputs.shape)\n",
        "        dw = np.zeros(self.weights.shape)\n",
        "        db = np.zeros(self.bias.shape)\n",
        "\n",
        "\n",
        "        F= output_error.shape[0]\n",
        "        # print(\"F=\",F,\"ForOutputErrorShapeInBackConv\")\n",
        "        output_error=np.reshape(output_error,(F,WW,HH))\n",
        "        \n",
        "        # print(\"output_errorInBackConvShape=\",output_error.shape)\n",
        "\n",
        "        for f in range(F):\n",
        "            for w in range(0, WW, self.s):\n",
        "                for h in range(0, HH, self.s):\n",
        "                    dw[f,:,:,:]+=output_error[f,w,h]*self.inputs[:,w:w+self.K,h:h+self.K]\n",
        "                    dx[:,w:w+self.K,h:h+self.K]+=output_error[f,w,h]*self.weights[f,:,:,:]\n",
        "\n",
        "        for f in range(F):\n",
        "            db[f] = np.sum(output_error[f, :, :])\n",
        "\n",
        "        self.weights -= learning_rate * dw\n",
        "        self.bias -= learning_rate * db\n",
        "        # print(\"conv's backward is done\")\n",
        "        return dx\n",
        "\n",
        "    def extract(self):\n",
        "        return {self.name+'.weights':self.weights, self.name+'.bias':self.bias}\n",
        "\n",
        "    def feed(self, weights, bias):\n",
        "        self.weights = weights\n",
        "        self.bias = bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhZYbVwxtd7c"
      },
      "outputs": [],
      "source": [
        "class Maxpooling2D:\n",
        "\n",
        "    def __init__(self, pool_size, stride):\n",
        "        self.pool = pool_size\n",
        "        self.s = stride\n",
        "        # print(\"pool_size(pooling layer)=\",self.pool)\n",
        "        # print(\"self.s(pooling layer)=\",self.s)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        C, W, H = inputs.shape\n",
        "        # print(\"InputsShape(pooling layer)=\",inputs.shape)\n",
        "        new_width =int((W - self.pool)/self.s + 1)\n",
        "        # print(\"new_width(pooling layer)=\",new_width)\n",
        "        new_height = int((H - self.pool)/self.s + 1)\n",
        "        # print(\"new_height(pooling layer)=\",new_height)\n",
        "        out = np.zeros((C, new_width, new_height))\n",
        "        for c in range(C):\n",
        "            for w in range(int(W/self.s)):\n",
        "                for h in range(int(H/self.s)):\n",
        "                    out[c, w, h] = np.max(self.inputs[c, w*self.s:w*self.s+self.pool, h*self.s:h*self.s+self.pool])\n",
        "        # print(\"pool's forward is done\")\n",
        "        return out\n",
        "\n",
        "    def backward(self,  output_error, learning_rate):\n",
        "        # print(\"output_errorInBackMax=\",output_error.shape)\n",
        "        C, W, H = self.inputs.shape\n",
        "        # print(\"C=\",C,\"W=\",W,\"H=\",H,\"ForOutputErrorShapeInBackMax\")\n",
        "        dx = np.zeros(self.inputs.shape)\n",
        "        \n",
        "        for c in range(C):\n",
        "            for w in range(0, W, self.pool):\n",
        "                for h in range(0, H, self.pool):\n",
        "                    # print(\"selectInput=\",self.inputs[c,w:w+self.pool,h:h+self.pool])\n",
        "                    # print(\"argmaxSelectInput=\",np.argmax(self.inputs[c,w:w+self.pool,h:h+self.pool]))\n",
        "                    st = np.argmax(self.inputs[c,w:w+self.pool,h:h+self.pool])\n",
        "                    # print(\"stShape=\",st.shape)\n",
        "                    (idx, idy) = np.unravel_index(st, (self.pool, self.pool))\n",
        "                    # print(\"idx=\",idx,\"idy=\",idy)\n",
        "                    dx[c, w+idx, h+idy] = output_error[c,int( w/self.pool), int(h/self.pool)]\n",
        "                    # print(\"dxshape=\",dx.shape)\n",
        "        # print(\"pool's backward is done\")\n",
        "        return dx\n",
        "\n",
        "    def extract(self):\n",
        "        return "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTrTMpTwtLXd"
      },
      "outputs": [],
      "source": [
        "class FCLayer:\n",
        "    def __init__(self, input_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        # print(\"input_size(FC layer)=\",self.input_size)\n",
        "        # print(\"output_size(FC layer)=\",self.output_size)\n",
        "        self.weights = np.random.randn(input_size, output_size) / np.sqrt(input_size + output_size)\n",
        "        self.bias = np.random.randn(1, output_size) / np.sqrt(input_size + output_size)\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        return np.dot(input, self.weights) + self.bias\n",
        "        # print(\"FC's forward is done\")\n",
        "\n",
        "    def backward(self, output_error, learning_rate):\n",
        "        # print(\"FCLayer's shape_output_error----In=\",output_error.shape)\n",
        "        input_error = np.dot(output_error, self.weights.T)\n",
        "        weights_error = np.dot(self.input.T, output_error)\n",
        "        # bias_error = output_error\n",
        "        \n",
        "        \n",
        "        self.weights -= learning_rate * weights_error\n",
        "        self.bias -= learning_rate * output_error\n",
        "        # print(\"FCLayer input_errorShape=\",input_error.shape)\n",
        "        # print(\"FC's backward is done\")\n",
        "        return input_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6nSYAB2sam3"
      },
      "outputs": [],
      "source": [
        "class ActivationLayer:\n",
        "    def __init__(self, activation, activation_prime):\n",
        "        self.activation = activation\n",
        "        self.activation_prime = activation_prime\n",
        "    \n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        return self.activation(input)\n",
        "        # print(\"Activation's forward is done\")\n",
        "    \n",
        "    def backward(self, output_error, learning_rate):\n",
        "        return output_error * self.activation_prime(self.input)\n",
        "        # print(\"Activation's backward is done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hl8LxP1lAEiN"
      },
      "outputs": [],
      "source": [
        "# bonus\n",
        "class FlattenLayer:\n",
        "    def __init__(self, input_shape):\n",
        "        self.input_shape = input_shape\n",
        "        # print(\"input_shape(Flatten layer)=\",self.input_shape)\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        return np.reshape(input, (1, -1))\n",
        "        # print(\"Flatten's forward is done\")\n",
        "    \n",
        "    def backward(self, output_error, learning_rate):\n",
        "        # print(\"Flatten's shape_output----In=\",output_error.shape)\n",
        "        # print(\"Flatten's shape_output\",(np.reshape(output_error, self.input_shape)).shape)\n",
        "        return np.reshape(output_error, self.input_shape)\n",
        "        # print(\"Flatten's backward is done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQeuIfkK3vyl"
      },
      "outputs": [],
      "source": [
        "# bonus\n",
        "class SoftmaxLayer:\n",
        "    def __init__(self, input_size):\n",
        "        self.input_size = input_size\n",
        "        # print(\"input_size(Softmax layer)=\",self.input_size)\n",
        "    \n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        tmp = np.exp(input)\n",
        "        self.output = tmp / np.sum(tmp)\n",
        "        # print(\"Softmax's forward is done\")\n",
        "        return self.output\n",
        "    \n",
        "    def backward(self, output_error, learning_rate):\n",
        "        # print(\"SoftmaxLayer's shape_output----In=\",output_error.shape)\n",
        "        input_error = np.zeros(output_error.shape)\n",
        "        out = np.tile(self.output.T, self.input_size)\n",
        "        # print(\"Softmax's backward is done\")\n",
        "        return self.output * np.dot(output_error, np.identity(self.input_size) - out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuPbn70Wt8Q7"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_prime(x):\n",
        "    return np.exp(-x) / (1 + np.exp(-x))**2\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def tanh_prime(x):\n",
        "    return 1 - np.tanh(x)**2\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(x, 0)\n",
        "\n",
        "def relu_prime(x):\n",
        "    return np.array(x >= 0).astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXY7jkUzuqEk"
      },
      "outputs": [],
      "source": [
        "def mse(y_true, y_pred):\n",
        "    return np.mean(np.power(y_true - y_pred, 2))\n",
        "\n",
        "def mse_prime(y_true, y_pred):\n",
        "    return 2 * (y_pred - y_true) / y_pred.size\n",
        "\n",
        "def sse(y_true, y_pred):\n",
        "    return 0.5 * np.sum(np.power(y_true - y_pred, 2))\n",
        "\n",
        "def sse_prime(y_true, y_pred):\n",
        "    return y_pred - y_true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-whGNp8Joaur",
        "outputId": "96c63318-16b7-4905-dee5-6ceb9f363bed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_train /= 255\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "x_train = x_train[0:100]\n",
        "y_train = y_train[0:100]\n",
        "\n",
        "x_test = x_test[0:500]\n",
        "y_test = y_test[0:500]\n",
        "x_test = x_test.astype('float32')\n",
        "x_test /= 255\n",
        "y_test = np_utils.to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oHQpwN8LpKiN",
        "outputId": "2c7867e1-f450-4642-98d6-1963a033cf96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In Conv's Init\n",
            "weightsConvLayer= [[[[ 1.71510807e-02 -1.39968253e-01  1.33214470e-02 -1.00775979e-01\n",
            "     4.16652216e-01]\n",
            "   [ 3.72383068e-01  1.22761949e-01 -5.80051991e-02  1.01784761e-01\n",
            "     2.00824842e-01]\n",
            "   [ 5.23919497e-02 -2.89716693e-01 -6.83187658e-03 -2.14073645e-03\n",
            "    -3.09944956e-01]\n",
            "   [ 4.19128814e-02  9.84182210e-02 -1.21962210e-01 -1.07738997e-02\n",
            "     6.02884783e-02]\n",
            "   [ 8.78321777e-02 -2.65479487e-01 -2.30242623e-01  3.40777861e-02\n",
            "     3.83202005e-02]]]\n",
            "\n",
            "\n",
            " [[[-2.02203752e-01 -1.33496245e-01  6.60157747e-02 -3.83181738e-01\n",
            "     3.08190132e-01]\n",
            "   [ 3.04623093e-01  8.94274056e-02 -1.46120988e-01 -6.17787606e-02\n",
            "     9.07174700e-02]\n",
            "   [-4.50998859e-01 -3.52770790e-01 -5.70319494e-04 -5.54668371e-02\n",
            "     3.00298057e-01]\n",
            "   [-6.59938938e-02  4.56098025e-02  6.18336266e-02  1.85460210e-01\n",
            "     1.00899613e-01]\n",
            "   [-7.80727429e-03 -5.91130184e-02  1.86896891e-01  3.68472686e-03\n",
            "     1.04517777e-01]]]\n",
            "\n",
            "\n",
            " [[[-1.55899204e-01  1.15286313e-01 -3.06410656e-02  4.78965573e-02\n",
            "     1.21749053e-01]\n",
            "   [ 5.04276891e-02 -2.44479862e-01 -2.48159158e-01 -3.52176634e-01\n",
            "    -1.81481418e-01]\n",
            "   [-3.47041336e-01  6.26545858e-02  2.00653145e-01 -2.75205075e-01\n",
            "     8.18971267e-02]\n",
            "   [ 1.99271323e-01 -5.50621253e-01  7.14911898e-02 -8.28201002e-02\n",
            "    -3.94342375e-04]\n",
            "   [-1.57656698e-02  1.71586161e-01 -1.33036427e-03 -2.82111634e-01\n",
            "     4.08987277e-01]]]\n",
            "\n",
            "\n",
            " [[[-1.23168012e-01 -3.63133201e-01 -1.63373793e-01 -7.54438862e-02\n",
            "     7.20214051e-02]\n",
            "   [ 1.20214517e-01  3.97822848e-01  1.03504610e-01  1.93141564e-01\n",
            "     1.27971927e-02]\n",
            "   [ 1.37475338e-01  1.90482170e-01 -8.17887377e-02  7.48277294e-02\n",
            "     1.33500480e-01]\n",
            "   [-3.09398775e-01  1.91589963e-01  1.57794658e-01 -1.75369862e-01\n",
            "     3.08211077e-01]\n",
            "   [ 1.07360250e-01  2.32864582e-01  5.56370990e-02  6.27387706e-03\n",
            "     3.08314641e-01]]]\n",
            "\n",
            "\n",
            " [[[-2.54685477e-01 -5.20069408e-02 -2.45799999e-01 -5.61618365e-02\n",
            "     2.82984863e-02]\n",
            "   [ 2.41896351e-01 -2.51374659e-01  1.78328827e-01  2.29694401e-01\n",
            "     6.47239888e-02]\n",
            "   [ 1.61115193e-01  1.32266951e-01 -8.16529922e-02  1.87589900e-01\n",
            "     8.87157969e-02]\n",
            "   [ 2.50381702e-02  3.64537641e-02  2.14442238e-01  1.61630468e-01\n",
            "     2.09006796e-01]\n",
            "   [ 1.89621973e-01  6.15025122e-02  2.03086352e-01 -1.03633469e-01\n",
            "     4.91981543e-02]]]\n",
            "\n",
            "\n",
            " [[[-5.89602087e-02  6.22423947e-02  2.41448955e-01  2.23851927e-01\n",
            "     1.96973489e-02]\n",
            "   [ 1.57635120e-01  4.08869002e-02 -1.14272528e-02 -1.95167244e-01\n",
            "     1.61834837e-01]\n",
            "   [-1.95611338e-01  9.64714386e-02  4.57191588e-02  2.30107741e-01\n",
            "    -1.92539125e-01]\n",
            "   [ 2.04752720e-01  3.37183086e-01 -3.49180634e-01  2.94440852e-01\n",
            "    -1.00743258e-01]\n",
            "   [-2.88875087e-02 -3.08811192e-02 -6.13060405e-02  8.00059819e-02\n",
            "    -4.33405565e-01]]]]\n",
            "In Conv's Init\n",
            "weightsConvLayer= [[[[ 1.02013387e-01  1.86257946e-02  2.21375066e-02  8.06662751e-02\n",
            "    -1.97863319e-02]\n",
            "   [-3.84832904e-02  6.44590502e-02 -2.86474237e-02 -1.72836578e-01\n",
            "     7.68550844e-02]\n",
            "   [ 7.74119363e-02 -2.72918397e-02  1.20986885e-01 -8.54843619e-02\n",
            "    -5.71970111e-02]\n",
            "   [-2.51116068e-02  1.87292201e-01  7.48684232e-02 -1.46568239e-01\n",
            "    -5.10849551e-02]\n",
            "   [ 3.76237613e-02 -4.01248047e-02  1.12365513e-01 -4.17816076e-02\n",
            "     1.47711188e-01]]\n",
            "\n",
            "  [[-6.39982954e-02  4.77980582e-02 -9.54712188e-02  5.54440192e-02\n",
            "    -1.59469335e-01]\n",
            "   [-6.63168601e-02 -8.62948467e-02  1.53267732e-02 -1.90811711e-01\n",
            "     7.13369887e-02]\n",
            "   [-1.87600915e-01 -4.39787315e-02  3.31309126e-02 -4.66599898e-02\n",
            "    -6.75138344e-02]\n",
            "   [-5.87470520e-02 -1.56036691e-01  1.82238001e-01  4.43840062e-02\n",
            "    -9.83295984e-04]\n",
            "   [-4.78392963e-02  5.15690910e-02 -3.73621601e-03  1.56469923e-02\n",
            "    -4.45113062e-02]]\n",
            "\n",
            "  [[-6.26547582e-02 -5.75997571e-03 -3.71166157e-02  1.04412889e-01\n",
            "    -1.31918188e-01]\n",
            "   [ 2.40279486e-02  3.66213320e-02 -9.48186234e-02  1.14147140e-02\n",
            "    -1.18421416e-01]\n",
            "   [ 2.30031895e-01  3.86735185e-02  1.04578579e-01  7.18889404e-02\n",
            "    -4.40788584e-02]\n",
            "   [ 1.73292565e-02 -6.86544122e-02 -1.53047169e-03  3.08052308e-02\n",
            "     1.90141881e-02]\n",
            "   [-4.14043786e-03  2.20430098e-02 -3.71281951e-03 -5.91712264e-02\n",
            "     7.04919954e-02]]\n",
            "\n",
            "  [[ 5.96636989e-02  9.97207003e-02 -1.17623493e-01 -1.95403742e-02\n",
            "     5.21006443e-03]\n",
            "   [ 2.01436231e-02 -6.19528917e-02 -1.51621866e-01  1.44837791e-01\n",
            "     4.91385640e-03]\n",
            "   [ 5.62612476e-02 -4.62654790e-02  1.13497424e-02 -9.90947380e-02\n",
            "     1.27713367e-01]\n",
            "   [ 2.09836118e-01  1.60209385e-02 -6.84605574e-02  8.41997413e-03\n",
            "    -5.85319027e-02]\n",
            "   [ 4.92908570e-02 -2.16753862e-03 -8.08662947e-03 -8.32928754e-02\n",
            "     1.34628370e-01]]\n",
            "\n",
            "  [[ 2.50890885e-02 -1.03842320e-02  7.17297600e-02 -1.36815214e-01\n",
            "    -1.47251142e-02]\n",
            "   [-1.63679410e-01  7.69827521e-02  2.14699502e-01  2.33710543e-02\n",
            "     7.71778202e-03]\n",
            "   [ 2.03032993e-02  7.50025574e-02 -1.53582155e-02 -1.61960841e-02\n",
            "    -1.03379694e-01]\n",
            "   [ 1.08697690e-01 -5.45121313e-02  2.23655879e-01 -1.68249489e-02\n",
            "    -9.30642529e-02]\n",
            "   [ 1.08442105e-01 -8.41995913e-03  1.20509800e-01  4.30235176e-02\n",
            "    -9.85564029e-02]]\n",
            "\n",
            "  [[ 6.81339828e-02 -1.04122493e-01 -1.80821346e-02  7.68329329e-02\n",
            "    -6.59093709e-02]\n",
            "   [ 2.13136566e-02 -1.13986917e-01 -7.42313494e-03 -4.11343405e-02\n",
            "     9.82644811e-02]\n",
            "   [ 2.88226159e-02 -6.85687641e-03  6.18471789e-02 -1.41420425e-02\n",
            "    -4.10150313e-02]\n",
            "   [-2.74429493e-02 -1.67563342e-02  3.16893084e-02 -8.11272299e-02\n",
            "     8.44037567e-03]\n",
            "   [-1.74941312e-01  1.77273512e-02  1.08114545e-01 -6.27879474e-03\n",
            "    -5.67518357e-02]]]\n",
            "\n",
            "\n",
            " [[[ 5.32447774e-02 -3.80865612e-03 -5.31337049e-02  8.88015921e-02\n",
            "     8.56418391e-03]\n",
            "   [ 3.05379917e-01  4.48183364e-02  7.43179983e-02 -1.42961113e-01\n",
            "     1.91233171e-01]\n",
            "   [ 5.85720405e-02 -6.88161038e-02 -5.28904591e-02  1.46099000e-01\n",
            "    -1.30258661e-01]\n",
            "   [ 6.49967788e-03 -4.70642179e-02 -1.03913370e-01  7.24730606e-02\n",
            "     3.21333275e-02]\n",
            "   [-1.27545383e-01 -7.89763617e-02  2.68151256e-02 -6.75240265e-02\n",
            "     1.67568661e-02]]\n",
            "\n",
            "  [[-2.11137452e-02  1.24046054e-01  3.89324382e-02  2.20666531e-01\n",
            "    -1.66442273e-02]\n",
            "   [ 8.17208337e-02 -9.80129232e-02  2.30463128e-02 -4.33727798e-02\n",
            "     1.44676459e-01]\n",
            "   [-4.49255765e-03 -1.68577350e-01 -1.37072503e-03  1.11164379e-01\n",
            "     2.37781240e-02]\n",
            "   [-7.09973869e-02  1.49533006e-01 -4.54251908e-03  3.32404279e-02\n",
            "     3.76472328e-02]\n",
            "   [-5.89626526e-02  1.06885139e-02 -7.68771416e-02  1.33560912e-01\n",
            "     5.46283313e-03]]\n",
            "\n",
            "  [[ 1.31684383e-01  9.97402909e-02  1.18855106e-02 -1.88872589e-02\n",
            "    -4.79128607e-02]\n",
            "   [ 2.55475772e-02  1.18173703e-01 -2.70018260e-02 -1.07876894e-02\n",
            "     3.79933629e-02]\n",
            "   [ 1.14470937e-01 -1.41623247e-01  9.70386454e-02 -8.66114171e-03\n",
            "    -8.92036533e-03]\n",
            "   [ 9.83218414e-02 -7.10157535e-02  3.33078491e-02 -2.04396682e-01\n",
            "     1.43197708e-01]\n",
            "   [ 5.97700711e-02 -3.49714054e-02 -7.84753329e-02  7.83357618e-03\n",
            "     6.51457178e-03]]\n",
            "\n",
            "  [[-4.10297081e-02  9.09909116e-03  2.30306802e-02 -5.09473768e-02\n",
            "     5.83414956e-02]\n",
            "   [ 5.60591933e-03  6.35096966e-02 -3.13873082e-02  1.05986813e-01\n",
            "    -3.08799429e-02]\n",
            "   [ 6.12609535e-02 -1.00417941e-01 -7.53925008e-02 -4.85381539e-02\n",
            "     1.11393160e-01]\n",
            "   [ 2.09527329e-02  1.78815077e-01  5.58424388e-02 -1.08940535e-01\n",
            "    -7.03704086e-02]\n",
            "   [ 1.16735183e-01  9.32448932e-02  9.59284091e-02 -1.63051044e-01\n",
            "    -7.13415923e-02]]\n",
            "\n",
            "  [[-1.39992770e-01 -6.41092056e-02  7.62228388e-02 -3.65566659e-02\n",
            "    -3.61553290e-02]\n",
            "   [-9.20692603e-02 -7.22854095e-03  1.14016618e-01  1.90237684e-01\n",
            "    -1.72383524e-02]\n",
            "   [-1.03299750e-02  9.72750307e-03  1.13921168e-01 -1.84347453e-02\n",
            "     1.10697693e-02]\n",
            "   [-1.05237967e-01  2.20776285e-02  1.55359436e-02  8.72687482e-02\n",
            "    -1.45866397e-01]\n",
            "   [ 1.03627571e-01  1.59411797e-02 -5.26987627e-02  8.04391252e-02\n",
            "    -5.60567512e-03]]\n",
            "\n",
            "  [[-2.18303270e-02  1.64667851e-02 -1.22907546e-01 -1.43725281e-02\n",
            "    -1.41068412e-01]\n",
            "   [-1.68593970e-02  1.33985241e-01 -2.14366184e-03  9.79911475e-02\n",
            "    -5.46197316e-02]\n",
            "   [-6.88868572e-02 -1.51801820e-01  1.74192991e-02  5.67774407e-02\n",
            "     8.52394545e-03]\n",
            "   [ 1.14988642e-01 -1.04222204e-01 -2.08436165e-02 -3.47762836e-02\n",
            "    -1.91367920e-02]\n",
            "   [ 8.42349152e-02  1.48051031e-02 -7.93743794e-02  1.72249545e-02\n",
            "    -7.07422090e-02]]]\n",
            "\n",
            "\n",
            " [[[ 1.13550636e-01 -1.93897820e-01 -1.38087722e-02 -1.03361293e-01\n",
            "    -2.02706464e-02]\n",
            "   [ 1.30741616e-01 -1.54265656e-02 -1.10489272e-01  8.61570766e-02\n",
            "    -3.32294144e-02]\n",
            "   [-7.69669446e-02  5.19287321e-02  6.63143594e-02  2.95719333e-02\n",
            "    -8.82431757e-02]\n",
            "   [-9.32451319e-02 -9.47987932e-02  6.81174231e-02  7.28695042e-02\n",
            "     1.23483462e-01]\n",
            "   [-9.01906230e-03 -2.02046076e-02  2.54552247e-02 -7.99439562e-02\n",
            "     2.11280941e-02]]\n",
            "\n",
            "  [[ 3.44330959e-03 -3.14636869e-02 -6.48380482e-04  1.67745012e-01\n",
            "     1.31215820e-02]\n",
            "   [ 1.97904782e-02 -2.90029400e-02  2.39823578e-02 -6.23293029e-02\n",
            "    -3.48445088e-02]\n",
            "   [-1.17875624e-01 -8.44304221e-02 -1.94583755e-02  3.60274652e-02\n",
            "     1.09192005e-01]\n",
            "   [ 3.52818206e-02  9.82814420e-02  8.51620377e-02 -5.38360860e-02\n",
            "     8.40389262e-02]\n",
            "   [ 7.26517086e-02  2.97876174e-02  7.55138963e-02 -3.37228132e-02\n",
            "     8.51607819e-03]]\n",
            "\n",
            "  [[-9.19360260e-02  5.84961419e-02 -1.78788727e-01  1.20876186e-02\n",
            "    -1.57598842e-01]\n",
            "   [ 3.57477018e-02  3.20482272e-02  6.63286837e-02 -4.00255218e-02\n",
            "    -9.12435411e-02]\n",
            "   [ 2.44642916e-01 -3.99887770e-02 -5.17044379e-02  1.31613724e-02\n",
            "    -3.67168909e-02]\n",
            "   [ 9.03333984e-03  3.48177042e-02  1.92526216e-02 -1.92095953e-02\n",
            "     1.52517696e-02]\n",
            "   [ 5.18511309e-02 -1.17601734e-01 -8.99302280e-02  9.61043011e-02\n",
            "    -4.66070150e-02]]\n",
            "\n",
            "  [[-3.51637398e-02 -1.57854904e-02  1.22819978e-01  6.63823295e-03\n",
            "     5.43826814e-03]\n",
            "   [-4.42496657e-02 -4.91902153e-02 -3.54597184e-02  2.92241429e-02\n",
            "    -7.23136593e-02]\n",
            "   [-1.33363577e-01  2.05536225e-02 -6.48463747e-02  6.75638497e-02\n",
            "    -3.10288266e-02]\n",
            "   [-7.18363412e-02  4.52824065e-02  2.29765443e-02 -1.14515221e-01\n",
            "    -1.77278794e-01]\n",
            "   [ 1.42810261e-02  3.45001418e-02  2.91907316e-02 -4.47686705e-02\n",
            "     7.35733403e-02]]\n",
            "\n",
            "  [[ 6.53092608e-02  1.19368355e-01  1.10356696e-01 -7.79022479e-02\n",
            "    -2.27236339e-02]\n",
            "   [ 1.61100937e-01  3.21250434e-02  7.17479690e-02  3.73954314e-02\n",
            "    -1.04644550e-01]\n",
            "   [ 1.51181130e-02 -3.56721212e-02 -2.92036507e-02  6.02275071e-03\n",
            "     4.09065812e-02]\n",
            "   [ 1.31908769e-01 -2.14998221e-01  1.54437105e-02  1.78078685e-01\n",
            "     1.99349701e-02]\n",
            "   [-4.80785168e-02 -4.03494258e-02  8.47067218e-02  7.97222168e-02\n",
            "    -1.24902916e-02]]\n",
            "\n",
            "  [[ 9.43647524e-02 -1.45865659e-01  2.62081265e-02  1.69437222e-01\n",
            "     1.00679681e-01]\n",
            "   [-1.17428022e-01  8.26315542e-04 -5.10181181e-02 -1.12564828e-01\n",
            "     1.10715010e-01]\n",
            "   [-1.37647046e-01  1.15902001e-01  1.00303657e-01 -1.01006894e-01\n",
            "    -6.19785974e-02]\n",
            "   [ 7.54395234e-02 -1.61236413e-02 -5.26654881e-02 -1.03536063e-01\n",
            "    -8.47535415e-03]\n",
            "   [-7.75294915e-03  3.59082905e-02 -5.16294041e-02  7.65965200e-02\n",
            "     3.44688261e-02]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 1.75148191e-02  6.60243942e-02 -6.14371681e-02 -6.27012953e-04\n",
            "     8.70758061e-02]\n",
            "   [-7.48217611e-02  1.44585083e-01 -1.80838545e-02 -4.75789453e-02\n",
            "     2.88741612e-02]\n",
            "   [ 6.39633508e-02  1.10368763e-01 -5.64122534e-02 -1.12889375e-01\n",
            "    -4.63507370e-02]\n",
            "   [ 4.87068212e-02 -4.84565506e-02  4.09808965e-02 -4.02710852e-02\n",
            "     1.40433859e-01]\n",
            "   [ 7.71077885e-02  2.99191629e-02  4.64074227e-02  9.27092109e-02\n",
            "     4.59062360e-02]]\n",
            "\n",
            "  [[ 3.40229072e-02 -2.24064646e-02 -7.31712986e-02  5.69811088e-02\n",
            "     1.19271839e-01]\n",
            "   [-6.35094220e-02 -1.13751100e-02 -8.16361644e-02 -4.10114718e-02\n",
            "     1.11373984e-02]\n",
            "   [ 2.93713205e-02  4.95231113e-03  6.40192133e-02  3.89887382e-02\n",
            "     5.02055746e-02]\n",
            "   [-3.53170691e-02 -1.02715116e-01  3.44296097e-02 -6.91224388e-02\n",
            "    -1.42372654e-03]\n",
            "   [-1.07673503e-01 -7.63413191e-02  7.23976486e-02  5.68378544e-02\n",
            "     9.36864346e-03]]\n",
            "\n",
            "  [[ 6.58964067e-02 -6.36315828e-03 -1.91019959e-02  4.91216301e-02\n",
            "    -1.73889820e-02]\n",
            "   [-3.36591324e-03  6.58173002e-03  5.88578342e-02  3.33164730e-02\n",
            "    -1.12129283e-01]\n",
            "   [-8.67822070e-02  1.17291561e-02 -1.49925804e-01 -1.19212726e-01\n",
            "    -1.04936288e-02]\n",
            "   [ 4.01802420e-02 -2.16829969e-02  3.11622740e-03  1.14199337e-01\n",
            "    -4.93069491e-02]\n",
            "   [-3.31270739e-02  1.44619622e-01 -8.12483881e-02  1.20366880e-01\n",
            "    -9.55975451e-02]]\n",
            "\n",
            "  [[-1.35455141e-01 -2.73013953e-02  9.38918755e-02  1.57803058e-01\n",
            "     1.23034692e-01]\n",
            "   [ 4.93323759e-02  2.15857227e-02 -3.55287786e-02 -4.03125141e-02\n",
            "     6.05986142e-02]\n",
            "   [-2.75036389e-02  2.99193442e-02  6.83092716e-02  2.63096398e-02\n",
            "    -6.15198258e-02]\n",
            "   [ 1.05923292e-01  5.38123282e-02 -6.60345869e-04  8.77621788e-02\n",
            "     1.80678624e-02]\n",
            "   [-9.18911710e-02 -7.45701454e-02 -1.82734950e-01  2.19708726e-02\n",
            "    -4.69626223e-02]]\n",
            "\n",
            "  [[-2.53839679e-01 -4.59928203e-02 -4.74330535e-02  7.61677633e-02\n",
            "     1.29783527e-02]\n",
            "   [-1.21887210e-02 -3.13477903e-03 -1.31089032e-02 -1.46836037e-02\n",
            "    -5.65318214e-02]\n",
            "   [-2.02599048e-02 -1.13048800e-01  1.67821555e-01 -2.07952973e-02\n",
            "     2.09744764e-01]\n",
            "   [-6.07953785e-02 -1.96781770e-01 -7.85288033e-02 -8.91628053e-02\n",
            "    -3.57834472e-02]\n",
            "   [-4.87755935e-02 -9.60935863e-02 -8.90963086e-02 -9.61667540e-03\n",
            "     9.26927243e-02]]\n",
            "\n",
            "  [[-7.44047168e-02 -1.65622105e-04  5.61653320e-02 -7.70886304e-02\n",
            "     1.14887007e-01]\n",
            "   [-5.41889749e-02  5.02648701e-02 -2.31934586e-02  3.07350383e-02\n",
            "    -6.17040551e-02]\n",
            "   [-1.47438350e-01  8.21912137e-02  7.72183454e-02 -8.52970296e-02\n",
            "    -4.28163396e-02]\n",
            "   [-8.14577910e-02  4.20143474e-02  1.53402066e-02 -7.86243407e-02\n",
            "    -1.36138247e-01]\n",
            "   [-3.93002953e-02  2.90257854e-02  3.43217043e-02 -3.34310824e-03\n",
            "     7.81407325e-02]]]\n",
            "\n",
            "\n",
            " [[[ 1.70059661e-02 -1.82780612e-02  1.27336406e-01  1.42977514e-01\n",
            "     6.91930435e-02]\n",
            "   [-6.99480466e-02  4.07378524e-02  3.10516996e-02  9.70602899e-02\n",
            "     1.83457870e-04]\n",
            "   [ 5.60909578e-02 -1.33130285e-01 -7.36714899e-03 -1.42603496e-02\n",
            "     1.17687817e-01]\n",
            "   [-1.00946814e-01  5.01909391e-02 -3.49877900e-02  1.35163279e-02\n",
            "    -8.01078814e-02]\n",
            "   [ 3.46077366e-02  6.78197021e-02 -9.19501370e-02 -1.13243901e-01\n",
            "    -7.84630871e-02]]\n",
            "\n",
            "  [[-2.81150468e-02 -2.30279458e-02  1.80401298e-02 -2.06497538e-02\n",
            "    -4.73142713e-02]\n",
            "   [-2.85580934e-02 -1.04781102e-01  1.21882282e-01 -2.79383021e-02\n",
            "     7.02999856e-02]\n",
            "   [ 1.41935936e-01  4.23604849e-02 -1.40981969e-02  1.16351705e-02\n",
            "     6.83643399e-02]\n",
            "   [-1.03499362e-01  1.39890960e-02  1.00438466e-01 -9.97001947e-02\n",
            "    -8.96130909e-02]\n",
            "   [ 1.47370827e-02  1.24309653e-02 -3.47437828e-02 -2.11925785e-01\n",
            "    -7.19148975e-02]]\n",
            "\n",
            "  [[ 7.76242265e-02 -5.93256659e-02 -4.91674950e-02 -1.31236970e-01\n",
            "     8.45346780e-02]\n",
            "   [ 8.50101703e-02 -9.61492826e-02  7.19857040e-03  5.57430300e-02\n",
            "     1.60250290e-02]\n",
            "   [ 6.78650500e-02 -6.56799542e-02  3.87583647e-02 -8.28347556e-02\n",
            "    -8.10614785e-02]\n",
            "   [-1.85598142e-01  4.38971352e-02 -1.06717604e-01  2.54825681e-02\n",
            "     7.95262575e-03]\n",
            "   [ 2.68501576e-03  4.63333159e-02 -1.21069984e-01  1.23158233e-01\n",
            "    -7.42181958e-02]]\n",
            "\n",
            "  [[-1.08580261e-01  6.92001137e-02  9.98437366e-02 -7.45845886e-02\n",
            "    -7.54146258e-02]\n",
            "   [-1.06229792e-01  1.04217346e-02  1.27294997e-01  1.48619648e-02\n",
            "    -2.19986110e-02]\n",
            "   [-5.68959360e-02 -8.22046373e-02  6.25189564e-04 -2.19229171e-02\n",
            "     5.13915139e-02]\n",
            "   [-6.09533457e-02  1.24824049e-01 -1.61036993e-01  5.79226618e-02\n",
            "    -9.60518598e-02]\n",
            "   [ 1.10474075e-01 -1.20093001e-01 -1.28268560e-02  1.03456372e-01\n",
            "     1.62793133e-03]]\n",
            "\n",
            "  [[-6.07732749e-02  4.39851555e-03  4.40411126e-02  2.98504983e-02\n",
            "    -4.34606099e-02]\n",
            "   [ 6.03905488e-02  1.61127861e-02  4.67508988e-02  3.32677065e-02\n",
            "    -6.82039579e-02]\n",
            "   [-5.28723566e-02  3.16512505e-02 -1.38036894e-01  1.27861733e-02\n",
            "     5.40237913e-02]\n",
            "   [-1.63846861e-01  1.42707815e-02 -8.99747765e-02 -6.18608927e-02\n",
            "    -1.13082980e-01]\n",
            "   [ 1.68162374e-01  7.83637916e-02 -2.42424794e-01 -7.67787099e-02\n",
            "     6.97613710e-02]]\n",
            "\n",
            "  [[ 1.09522591e-01  6.95662833e-02 -4.60920065e-02  1.94712585e-01\n",
            "    -8.14788076e-02]\n",
            "   [-4.66997807e-02 -1.13544472e-02  3.36713340e-02 -2.40384470e-02\n",
            "    -4.07897447e-02]\n",
            "   [-9.03139160e-02 -1.13148372e-02 -1.00926763e-01  9.15033695e-02\n",
            "     4.38624828e-03]\n",
            "   [ 5.37796830e-02  1.85785578e-02 -3.41764496e-03 -3.01746201e-02\n",
            "    -5.92902371e-02]\n",
            "   [-5.91101167e-02  1.01386166e-01  2.15396270e-02  1.86817574e-03\n",
            "     1.11644375e-01]]]\n",
            "\n",
            "\n",
            " [[[ 6.04473651e-02 -2.49194597e-02  1.24033719e-01  9.60244247e-02\n",
            "    -2.44889277e-02]\n",
            "   [ 6.56274435e-02 -3.41193070e-02  1.14924053e-01 -1.88307294e-01\n",
            "    -5.50668554e-02]\n",
            "   [ 1.42388346e-01  1.87605606e-01  1.81396634e-01 -2.15887953e-02\n",
            "     1.97729158e-02]\n",
            "   [-9.80330171e-02  3.59253429e-02 -1.02111608e-01 -5.91418643e-02\n",
            "    -1.88499756e-02]\n",
            "   [-8.08740093e-02 -6.11438019e-02  1.98418057e-01  7.18086096e-02\n",
            "     1.89478703e-01]]\n",
            "\n",
            "  [[ 2.38153720e-02  1.47304716e-01 -4.04855386e-02 -1.41281799e-01\n",
            "     7.41281597e-02]\n",
            "   [ 4.26564321e-02 -4.48036369e-02  1.07480585e-01  6.25535625e-04\n",
            "    -1.10897284e-02]\n",
            "   [ 1.24895615e-01 -5.21733516e-02  1.76604886e-02 -1.76145995e-01\n",
            "    -6.52354099e-03]\n",
            "   [-4.82022485e-02  7.76375844e-02 -6.55141908e-02  1.60829696e-01\n",
            "    -3.09343538e-02]\n",
            "   [-2.15864812e-01 -2.65839066e-03  1.77616700e-01  3.12781445e-02\n",
            "    -1.90649088e-01]]\n",
            "\n",
            "  [[-5.58926896e-02  3.78449117e-02  1.20999144e-02  5.65114331e-02\n",
            "     9.60360384e-02]\n",
            "   [-1.10795245e-01  6.80571389e-02 -4.86293717e-02  1.44744936e-01\n",
            "     7.64493607e-03]\n",
            "   [-1.36100393e-01 -2.74019962e-03 -8.34946576e-02  3.01866734e-02\n",
            "     2.13876506e-01]\n",
            "   [ 2.20353810e-02 -9.16517554e-02 -7.32152983e-02  3.67093768e-03\n",
            "    -2.59215368e-02]\n",
            "   [ 2.56785041e-02 -5.02387778e-02 -1.92470273e-02 -1.22088985e-02\n",
            "    -9.15428556e-03]]\n",
            "\n",
            "  [[-6.91797816e-02 -6.38902928e-02 -2.11473300e-01  4.22676346e-02\n",
            "    -1.78788854e-02]\n",
            "   [-4.40237166e-02 -1.06877575e-01  8.46202183e-02 -1.13038473e-01\n",
            "     4.47931359e-02]\n",
            "   [-4.15680710e-02 -1.40844099e-01 -3.61386282e-02 -1.51316118e-01\n",
            "    -1.23349659e-01]\n",
            "   [ 1.61338662e-02  5.44468541e-02  3.73608554e-02  3.66657280e-02\n",
            "    -4.10513567e-02]\n",
            "   [ 1.10971024e-01  3.02751999e-02  1.21547249e-01 -2.08277545e-01\n",
            "     1.03383160e-01]]\n",
            "\n",
            "  [[-1.02297007e-01 -1.27013131e-01 -5.71339038e-02 -4.67169398e-02\n",
            "     1.35237339e-01]\n",
            "   [-3.30110119e-02 -1.13906500e-01 -1.28984759e-01  1.34512714e-02\n",
            "    -1.51569964e-02]\n",
            "   [ 2.20774293e-02  5.20452842e-02  1.10558002e-02  6.22639735e-02\n",
            "     1.80651963e-01]\n",
            "   [-4.03691172e-02 -1.26300697e-01 -5.26028421e-02 -1.55192102e-01\n",
            "    -6.22733171e-02]\n",
            "   [-1.03984549e-01  9.73785507e-02  6.44367755e-02 -4.97819539e-02\n",
            "    -1.11122328e-01]]\n",
            "\n",
            "  [[ 2.20188944e-01 -9.02442776e-02  1.67481465e-02 -1.25600183e-01\n",
            "     6.35833941e-03]\n",
            "   [ 3.84854187e-02 -1.35684552e-01 -1.35122198e-01 -9.34548842e-02\n",
            "    -2.87165050e-02]\n",
            "   [ 7.35677182e-02 -3.78230565e-02  5.19040257e-02 -1.27810187e-02\n",
            "    -7.40995529e-02]\n",
            "   [ 6.25859681e-03  1.00094042e-01  1.74178847e-01 -5.04254336e-02\n",
            "     9.17016754e-02]\n",
            "   [ 2.93503196e-01 -1.13608121e-01 -9.23645336e-03 -1.04084200e-01\n",
            "     7.26646053e-02]]]]\n",
            "In Conv's Init\n",
            "weightsConvLayer= [[[[ 5.33487715e-03 -7.51500415e-02 -5.11990597e-02  6.38231834e-02\n",
            "    -1.90858474e-02]\n",
            "   [-2.91619302e-02 -1.66430291e-02 -1.08725824e-02 -4.95662355e-02\n",
            "    -1.65045908e-02]\n",
            "   [-5.44391512e-02  4.02122183e-02 -5.48506913e-03 -5.50244620e-03\n",
            "     2.58770717e-02]\n",
            "   [ 1.72220100e-02 -1.13656717e-02  2.05364004e-02 -1.07650958e-01\n",
            "     5.59028491e-02]\n",
            "   [-1.00928195e-02 -5.96967671e-02 -8.61918143e-02  6.97938615e-02\n",
            "     5.40315104e-03]]\n",
            "\n",
            "  [[-6.75620636e-02 -1.04221820e-01 -1.08921774e-01  1.43797126e-01\n",
            "    -1.34661731e-01]\n",
            "   [-4.84942204e-02 -9.10440231e-03 -1.83184516e-02  1.94984710e-03\n",
            "    -2.62745048e-02]\n",
            "   [ 5.16522227e-03  7.25252899e-02 -8.30014465e-04  5.92057795e-02\n",
            "    -1.62485535e-03]\n",
            "   [ 6.06685951e-02 -1.37897983e-02  1.00483535e-02  2.95372489e-02\n",
            "    -5.09140081e-02]\n",
            "   [ 7.20855853e-02 -6.26086088e-02 -6.03989458e-02 -2.15405629e-02\n",
            "     6.18163099e-02]]\n",
            "\n",
            "  [[ 3.50127454e-02 -1.91571962e-02  8.66870198e-02  1.88180463e-02\n",
            "     2.62342248e-02]\n",
            "   [ 5.76202508e-02  5.38558051e-02  7.73866846e-02  3.01830506e-02\n",
            "    -2.30264823e-02]\n",
            "   [ 5.15899275e-02 -2.73851095e-02  6.78049966e-02  1.17635176e-02\n",
            "     6.16343072e-02]\n",
            "   [ 6.85039364e-02  5.75658079e-02  3.75330659e-02 -4.25442179e-02\n",
            "    -1.91934961e-02]\n",
            "   [ 1.62777795e-02  5.29977273e-02 -5.39077236e-02  7.00890156e-02\n",
            "    -2.90488223e-02]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 4.92475965e-02 -1.36466710e-02 -8.17761773e-02 -6.54362338e-03\n",
            "    -5.23514388e-02]\n",
            "   [-5.78138879e-02  4.99555876e-02 -1.04206853e-02  1.05043377e-02\n",
            "     2.57423483e-02]\n",
            "   [ 4.50232055e-02 -5.07927611e-02  4.07912488e-02 -5.92880308e-03\n",
            "     9.17237517e-03]\n",
            "   [-2.91759842e-02 -1.22891939e-02  2.83480030e-02  3.43958805e-02\n",
            "     4.12205057e-02]\n",
            "   [-4.77196709e-03 -2.35071464e-02 -4.70971859e-02  3.67572641e-02\n",
            "     1.28822630e-02]]\n",
            "\n",
            "  [[ 9.78505908e-02 -2.35718236e-02 -2.11985274e-02  2.78228880e-02\n",
            "     2.87806031e-03]\n",
            "   [ 7.08171980e-02  2.51565265e-03  2.48465626e-03  1.16057967e-02\n",
            "    -4.35481741e-03]\n",
            "   [-9.08337260e-02  3.24292823e-02 -6.63883848e-02  4.72759888e-02\n",
            "     6.24944237e-02]\n",
            "   [ 3.14041034e-02  2.40503582e-02 -1.32859357e-02 -7.61247104e-02\n",
            "    -4.25793632e-02]\n",
            "   [-9.00419202e-02  5.51709085e-02 -3.38073976e-02 -7.66059752e-02\n",
            "     2.35154635e-02]]\n",
            "\n",
            "  [[-2.24237370e-02  4.77600022e-02  7.84930870e-02 -2.58971206e-03\n",
            "    -4.69442361e-02]\n",
            "   [-7.06151286e-02  3.21398233e-02  6.60973427e-02  1.07063597e-02\n",
            "    -4.97103737e-02]\n",
            "   [ 1.33172758e-01  1.50337269e-03 -2.46678522e-02 -4.03787455e-02\n",
            "    -4.85227108e-02]\n",
            "   [ 5.27562586e-03  1.02128383e-01 -1.27106272e-02 -6.05393223e-02\n",
            "    -1.06581699e-02]\n",
            "   [ 3.97187072e-02 -3.22293680e-02  4.73771128e-02  2.21322408e-02\n",
            "     3.70851504e-02]]]\n",
            "\n",
            "\n",
            " [[[-3.82801172e-02  9.48819268e-02 -3.38948062e-02  5.99335356e-02\n",
            "    -2.95169412e-02]\n",
            "   [ 6.93310044e-02  9.25917368e-03 -1.00887447e-02  2.27556693e-02\n",
            "    -6.01303449e-02]\n",
            "   [ 7.38547312e-02 -6.70397330e-03 -3.20822904e-02 -9.74491705e-03\n",
            "     6.29583850e-02]\n",
            "   [-5.62141929e-02  9.18811522e-03  3.52431259e-02  7.47149091e-03\n",
            "    -2.46250656e-02]\n",
            "   [-5.65235055e-02 -4.18657707e-02 -2.00658017e-02  2.63902163e-02\n",
            "     1.09547600e-02]]\n",
            "\n",
            "  [[ 4.04477789e-02 -5.42254929e-02  3.28280125e-02 -1.37227138e-02\n",
            "    -9.45140088e-03]\n",
            "   [-1.26477418e-01  2.64211662e-02  4.58024293e-02  2.68807638e-02\n",
            "    -1.32122383e-02]\n",
            "   [-2.41246628e-02 -1.83771611e-02 -9.37616514e-02  7.12795519e-02\n",
            "    -3.43053844e-02]\n",
            "   [ 2.00261330e-02 -3.59813548e-02  8.06753328e-03 -3.39724559e-02\n",
            "     2.67642920e-02]\n",
            "   [-2.80872832e-02 -4.63843724e-03  2.61269486e-02  9.16012539e-02\n",
            "     9.83980131e-02]]\n",
            "\n",
            "  [[-3.11100672e-02  4.15001646e-02  6.42603109e-03  4.48062252e-02\n",
            "     1.91136330e-02]\n",
            "   [ 1.30935570e-02  5.49848602e-02 -5.80776841e-03 -3.22262726e-03\n",
            "    -3.21064784e-02]\n",
            "   [ 2.97085129e-02  5.82550250e-02 -4.41485086e-02 -3.91854880e-02\n",
            "    -1.70971006e-02]\n",
            "   [ 1.18471128e-01  4.47898833e-02 -6.43977911e-02  6.17576389e-02\n",
            "     4.99117993e-02]\n",
            "   [-2.70391998e-02 -2.43134847e-02  6.03799445e-02 -9.44650319e-03\n",
            "    -2.50630714e-02]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 7.46666385e-03  3.56933026e-02 -8.06687373e-03  1.59296790e-03\n",
            "    -1.40475844e-03]\n",
            "   [-7.51366077e-03  6.49239858e-02 -7.57215229e-03  1.17644658e-01\n",
            "    -2.82380335e-02]\n",
            "   [ 4.83769945e-03  4.61660229e-02  6.68480908e-02 -8.23196730e-03\n",
            "    -2.08374528e-02]\n",
            "   [-8.04997829e-02 -5.06092565e-02 -5.94592833e-03  7.22158318e-02\n",
            "    -7.37539597e-02]\n",
            "   [-2.07523735e-02  1.72097678e-02 -9.06118799e-02 -3.64353817e-02\n",
            "     4.15034532e-03]]\n",
            "\n",
            "  [[-1.43785964e-02  5.63790364e-02 -8.80556238e-02  7.01917247e-03\n",
            "    -5.13062827e-02]\n",
            "   [ 2.60693271e-02  3.52737847e-03  3.85839423e-02  6.10805365e-02\n",
            "    -4.00293020e-02]\n",
            "   [ 7.26285271e-02  1.67359838e-02  1.02613659e-02  1.77141032e-02\n",
            "    -8.65963857e-02]\n",
            "   [ 3.56893552e-02  3.72025405e-02  6.21751256e-02 -1.51641375e-02\n",
            "    -6.08775147e-03]\n",
            "   [-5.22925142e-03 -4.76263799e-02 -1.03749389e-01 -2.62599867e-02\n",
            "    -5.58989345e-02]]\n",
            "\n",
            "  [[-3.64296113e-02  4.57659165e-02  4.94060583e-02  2.42022774e-02\n",
            "     2.60790528e-02]\n",
            "   [ 3.13025100e-03 -1.69412752e-02  7.12539662e-02  6.14623420e-02\n",
            "     3.15920664e-04]\n",
            "   [ 2.43989749e-02  4.23741486e-03  1.72745621e-02 -3.44326589e-02\n",
            "    -1.83886198e-02]\n",
            "   [-2.13671160e-02  3.33967835e-03 -2.71830569e-02 -3.84329212e-02\n",
            "    -9.25418922e-02]\n",
            "   [ 7.74256714e-02 -2.79007241e-03  2.91639090e-03 -6.95166609e-02\n",
            "    -4.39855851e-02]]]\n",
            "\n",
            "\n",
            " [[[ 6.45061365e-02  9.12100619e-02  1.31529832e-02 -6.25790469e-02\n",
            "    -1.14216255e-01]\n",
            "   [ 1.76340137e-02 -8.88597743e-02 -1.72751619e-02  5.69876718e-02\n",
            "    -5.14278431e-02]\n",
            "   [-3.08794522e-02  3.90096475e-02 -5.56228282e-02  2.29467454e-02\n",
            "    -4.89260908e-02]\n",
            "   [ 7.05754193e-02 -2.57061836e-03  4.23494158e-02  5.81501832e-03\n",
            "    -2.24089543e-02]\n",
            "   [ 2.83272033e-02 -1.20948426e-01 -4.15641969e-02 -7.84708631e-02\n",
            "     5.16149053e-02]]\n",
            "\n",
            "  [[-7.43060368e-02  9.81814954e-03 -3.99282540e-02 -1.10388456e-02\n",
            "    -2.47534512e-02]\n",
            "   [-3.86896620e-02  2.02062795e-02 -5.61102223e-02 -2.30369112e-02\n",
            "     9.08002318e-04]\n",
            "   [-2.83350224e-03 -1.46052517e-02 -1.07544889e-02  6.10106820e-02\n",
            "     2.05811416e-02]\n",
            "   [-1.79715445e-02 -6.78855354e-03 -6.14258194e-02 -9.98960961e-02\n",
            "     3.29686689e-02]\n",
            "   [-3.35090156e-02  5.03494229e-02  4.22636201e-02 -6.35347636e-03\n",
            "     2.87690055e-02]]\n",
            "\n",
            "  [[-3.43043589e-02 -2.37672588e-02  6.65635919e-02  1.31489961e-02\n",
            "     4.59155493e-02]\n",
            "   [ 1.98021471e-02  1.51758502e-02 -2.19625559e-02 -8.10814055e-02\n",
            "     1.50299805e-02]\n",
            "   [-4.02979409e-02  4.54316284e-02  1.46039897e-01  4.11049116e-02\n",
            "     5.52248619e-02]\n",
            "   [ 2.58140528e-02  8.95732893e-03 -2.15246841e-02 -5.25288177e-02\n",
            "     3.76738656e-02]\n",
            "   [-1.46149178e-02  4.53299607e-02 -3.23530642e-02  1.59864023e-02\n",
            "    -7.09893362e-02]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 7.60248893e-02 -6.75539138e-02 -5.20324648e-02  5.83807791e-02\n",
            "    -1.51555345e-02]\n",
            "   [ 3.70015992e-02 -1.87916170e-03 -3.09269867e-02  6.49581365e-02\n",
            "     8.88236546e-04]\n",
            "   [-4.34274263e-02  4.07612803e-02  1.19483076e-02 -1.80033219e-02\n",
            "    -7.04556707e-02]\n",
            "   [ 3.32133072e-02 -2.52895070e-02 -2.08753892e-02  6.81756522e-02\n",
            "     1.91054788e-02]\n",
            "   [ 1.72117450e-02 -1.20174032e-03 -3.43994155e-02  1.97879136e-02\n",
            "     9.96844961e-03]]\n",
            "\n",
            "  [[-2.94976553e-02 -2.02755820e-02  9.89611536e-03  8.02401842e-02\n",
            "     2.12222194e-02]\n",
            "   [-1.28705438e-03  4.98704591e-02 -2.11387705e-02 -2.30807723e-02\n",
            "    -3.88751996e-02]\n",
            "   [-2.40322054e-02  2.32768811e-02 -3.21322851e-02  3.08488320e-02\n",
            "    -1.07984003e-01]\n",
            "   [ 4.25164374e-02 -3.24709872e-02  6.42187838e-02  1.17453765e-01\n",
            "    -9.53654604e-02]\n",
            "   [-2.04575209e-02 -6.14501268e-02 -4.87124533e-02  3.34045500e-02\n",
            "    -6.14783078e-02]]\n",
            "\n",
            "  [[ 2.16629773e-02 -7.54896425e-02 -4.20623921e-03  1.58199187e-02\n",
            "    -4.87813254e-02]\n",
            "   [-5.97625544e-02  3.83299329e-02 -6.54320344e-02 -5.99130007e-03\n",
            "    -5.90885738e-02]\n",
            "   [ 1.48736369e-02 -5.28493888e-02 -4.92163724e-02 -3.27207617e-02\n",
            "    -2.34149919e-02]\n",
            "   [ 6.79297903e-02  2.82528487e-03 -4.59822155e-02 -5.82687121e-02\n",
            "     5.99340015e-02]\n",
            "   [ 6.50481716e-03 -1.67646492e-02  2.44783726e-02  3.92983265e-02\n",
            "     9.18482778e-03]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-1.28404722e-01  9.28337135e-02 -2.84506866e-02  1.06314067e-01\n",
            "    -3.57747263e-03]\n",
            "   [-2.76031930e-02 -3.04833285e-02 -4.51407509e-02 -5.98852737e-03\n",
            "     4.78748555e-02]\n",
            "   [ 6.55455182e-02  1.13051618e-02 -1.92913239e-02 -4.10358602e-02\n",
            "     2.64514241e-02]\n",
            "   [-2.64876129e-02 -6.06118447e-03  1.68628673e-02  2.80370175e-02\n",
            "    -2.75241734e-02]\n",
            "   [-4.47516759e-02 -7.15806813e-02  6.26795943e-02  3.16459187e-04\n",
            "     3.47695045e-02]]\n",
            "\n",
            "  [[ 5.87747044e-02  1.01380308e-02  6.87877598e-03 -3.60249997e-03\n",
            "    -7.14535424e-02]\n",
            "   [-4.93150427e-02 -4.70355674e-02  6.52810843e-03 -1.14369683e-02\n",
            "     2.40732040e-02]\n",
            "   [-1.97719637e-02 -1.37414793e-01 -5.19720130e-02 -8.32573249e-02\n",
            "     2.72648893e-02]\n",
            "   [-1.32307957e-02 -9.90979134e-03  4.98659184e-02 -3.33570713e-02\n",
            "     6.50184211e-04]\n",
            "   [-4.71830260e-02 -6.91554637e-02 -1.50140141e-02  5.50406855e-02\n",
            "    -1.47380024e-02]]\n",
            "\n",
            "  [[ 3.08018463e-02 -1.23620856e-01  4.56008484e-02 -2.46192619e-02\n",
            "    -2.61228185e-02]\n",
            "   [-2.16197978e-02 -8.49548063e-03 -3.44076126e-02  2.67390502e-02\n",
            "     4.14882408e-02]\n",
            "   [ 1.91288655e-03  3.64626159e-02 -5.27519452e-02  3.20337371e-02\n",
            "    -1.26741762e-01]\n",
            "   [ 3.72944693e-02 -9.29180499e-03  3.45056179e-02  1.24614674e-02\n",
            "     1.98108503e-02]\n",
            "   [ 5.86763266e-02 -2.22203849e-02  3.91938968e-02 -1.56530796e-02\n",
            "     3.05198579e-03]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 1.05386204e-01 -1.15373850e-04  7.89304585e-02 -9.39908792e-02\n",
            "    -2.48272377e-02]\n",
            "   [ 2.40846546e-02 -5.04739812e-02 -5.19975157e-02 -9.42333324e-03\n",
            "    -2.68376863e-02]\n",
            "   [-1.98816930e-02 -6.44126609e-02 -9.40401060e-03  7.46741412e-03\n",
            "    -4.37806879e-02]\n",
            "   [ 4.70838317e-02  4.78335746e-02 -8.05736522e-02  8.46453623e-02\n",
            "    -2.84352292e-02]\n",
            "   [ 2.96782463e-02 -1.05284629e-01  5.35774622e-02  1.93542448e-02\n",
            "     7.50956969e-02]]\n",
            "\n",
            "  [[-5.18360745e-02 -2.15401284e-02  2.77593172e-02 -4.01543714e-02\n",
            "    -7.97063590e-03]\n",
            "   [ 3.03567574e-02  5.35649832e-04 -3.97253578e-02  2.08852819e-02\n",
            "     2.18838702e-02]\n",
            "   [-1.81414657e-02  5.87813280e-03 -7.41539904e-02  2.35907564e-02\n",
            "    -6.10944522e-02]\n",
            "   [-1.45113338e-03 -2.52498278e-02 -4.49522234e-02 -4.02481243e-02\n",
            "     7.61379260e-02]\n",
            "   [-2.43956043e-02  8.30541049e-02  5.44582954e-02 -7.68141214e-02\n",
            "    -1.51833132e-02]]\n",
            "\n",
            "  [[ 1.62872830e-02 -8.88647395e-03 -5.84120477e-02  4.97154431e-03\n",
            "     7.44619975e-02]\n",
            "   [ 3.26014389e-02  2.83271589e-02 -4.12011436e-02 -2.05747590e-02\n",
            "    -2.91487970e-02]\n",
            "   [ 7.63361162e-03 -2.75987076e-02  3.79472103e-03  3.45066723e-02\n",
            "     1.97540073e-02]\n",
            "   [ 2.18380463e-02  2.82397478e-02  2.81720838e-02 -2.66388240e-02\n",
            "     3.81747634e-03]\n",
            "   [ 7.68133364e-02  8.95765860e-02  1.22573809e-02  3.19117551e-02\n",
            "    -1.79256698e-02]]]\n",
            "\n",
            "\n",
            " [[[-1.17607921e-02 -3.55978064e-02 -1.88626035e-02 -2.45473763e-02\n",
            "    -8.83133754e-02]\n",
            "   [ 6.85303507e-02 -5.95453286e-02  8.37478558e-03  2.00662530e-02\n",
            "     4.77404276e-02]\n",
            "   [ 1.49589756e-02 -3.36115401e-02  4.74707748e-02  7.36345077e-03\n",
            "     3.62685815e-02]\n",
            "   [ 6.54874069e-03 -1.24959153e-02 -8.96198372e-02  3.98598231e-02\n",
            "     4.98470010e-02]\n",
            "   [-2.10845794e-02  3.79848311e-02 -7.53018894e-02 -6.75760324e-02\n",
            "    -2.13902916e-02]]\n",
            "\n",
            "  [[-1.46637137e-02 -1.83683092e-02  5.83589156e-02  1.09536693e-01\n",
            "     2.10312652e-02]\n",
            "   [-3.35426665e-02 -5.43650373e-03  5.35490897e-04  8.65443231e-03\n",
            "    -5.26390348e-02]\n",
            "   [-3.15539907e-02 -6.18291458e-03 -6.22399996e-02  1.47196787e-02\n",
            "    -6.06119216e-02]\n",
            "   [-3.30425468e-02  2.72877792e-02  8.61343171e-02 -4.27739464e-02\n",
            "     2.32353856e-02]\n",
            "   [ 2.03308906e-02 -4.23028844e-02 -4.52524008e-02 -2.17627332e-02\n",
            "     4.43388131e-02]]\n",
            "\n",
            "  [[ 8.45561198e-03 -9.14781104e-04  1.61825517e-02  1.19172703e-01\n",
            "    -4.47309873e-02]\n",
            "   [-1.65585958e-02 -3.67173195e-02 -6.37940218e-02  2.20459238e-02\n",
            "    -7.76949214e-03]\n",
            "   [-4.67837869e-02  2.40955062e-02  3.77892819e-02 -5.95964243e-02\n",
            "     3.62662787e-02]\n",
            "   [ 2.14500207e-02  1.13572162e-01 -9.13310956e-02 -6.93100792e-02\n",
            "    -9.21533704e-02]\n",
            "   [ 5.68026191e-02 -6.40098980e-02  4.13523581e-03 -1.89599589e-02\n",
            "    -5.74529728e-02]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-6.95753634e-02  3.68609999e-02  1.48464649e-01  1.10572881e-01\n",
            "    -7.75968112e-02]\n",
            "   [-7.45332276e-02 -8.15360953e-02 -1.75829162e-02  2.27813702e-02\n",
            "     1.35237256e-02]\n",
            "   [-7.33229327e-02  3.78377582e-02 -4.13030529e-02 -1.47752222e-02\n",
            "     2.81189483e-02]\n",
            "   [ 7.05090143e-02 -1.83097797e-03 -1.27071322e-02 -4.23415020e-02\n",
            "     2.64063049e-02]\n",
            "   [ 1.06445029e-02  1.04039777e-01 -6.99728983e-02 -4.70387173e-02\n",
            "    -5.19844406e-03]]\n",
            "\n",
            "  [[ 3.47983290e-02 -3.05932912e-02 -9.30283793e-03  2.51092748e-02\n",
            "     9.94196997e-03]\n",
            "   [ 1.93477242e-02  1.41210460e-01  2.76630325e-02 -8.24528902e-02\n",
            "    -1.95354963e-02]\n",
            "   [ 3.27242445e-02  8.46123916e-02  4.03185941e-03 -9.16655700e-02\n",
            "    -4.14883709e-02]\n",
            "   [ 7.47188901e-03  1.66042114e-02  6.26834678e-02  2.74177802e-02\n",
            "    -5.95972781e-02]\n",
            "   [ 1.18729301e-02  6.95555914e-02 -4.38414758e-03 -3.37900567e-02\n",
            "     1.17328702e-01]]\n",
            "\n",
            "  [[ 2.34747347e-02 -3.47657190e-03 -1.07608498e-01 -2.91405966e-02\n",
            "     6.95456417e-02]\n",
            "   [ 3.03633023e-02  1.55506543e-02 -4.51253612e-02 -2.57584731e-02\n",
            "     8.42893002e-02]\n",
            "   [ 2.70806695e-02  8.65029362e-02  2.13900394e-02  8.13709170e-02\n",
            "    -7.79745590e-03]\n",
            "   [-2.91491399e-02  1.00115710e-01 -3.99674356e-02  3.99606734e-02\n",
            "    -2.37946578e-02]\n",
            "   [ 8.15586920e-02  5.55665709e-03 -8.54598569e-02 -2.11496109e-02\n",
            "     4.57984718e-02]]]\n",
            "\n",
            "\n",
            " [[[ 5.77560370e-03 -1.82548488e-02  9.40757233e-02  9.58804955e-02\n",
            "     1.80774299e-02]\n",
            "   [ 9.10062431e-03 -1.17703457e-03  3.63709507e-03  4.23229491e-02\n",
            "     4.88344984e-02]\n",
            "   [ 3.39523469e-02 -1.64615959e-02  1.25362670e-01 -7.10201076e-02\n",
            "     7.42323895e-02]\n",
            "   [ 4.88628069e-02  6.21477729e-02 -2.34617900e-02 -3.22787021e-02\n",
            "    -1.97555958e-02]\n",
            "   [-7.35289717e-02 -3.62462863e-02  3.51892638e-02  8.01229916e-02\n",
            "     3.99652307e-02]]\n",
            "\n",
            "  [[ 8.50269815e-03 -2.99094547e-02  7.63805588e-03  2.46475761e-02\n",
            "    -2.67337863e-02]\n",
            "   [-1.02211176e-01 -1.07572925e-01 -3.39541767e-02 -4.59064403e-02\n",
            "    -1.87218945e-02]\n",
            "   [ 2.15382494e-02 -8.30018222e-02  1.35440734e-02  2.12346610e-02\n",
            "     2.84241998e-02]\n",
            "   [ 1.03260229e-02  2.92825596e-02  6.83263506e-03 -3.98645026e-02\n",
            "     1.12832273e-03]\n",
            "   [ 2.95315268e-02 -3.77464017e-02  6.72583098e-02  7.30498263e-02\n",
            "     3.96496506e-03]]\n",
            "\n",
            "  [[-2.73563688e-02  7.81118609e-02  6.16790585e-02 -2.73186212e-02\n",
            "    -5.19970046e-02]\n",
            "   [ 9.26259479e-02  5.58492674e-02 -2.63743104e-02 -1.61961051e-02\n",
            "    -1.03482603e-01]\n",
            "   [-1.00762217e-02  8.16697255e-02  3.37602366e-04 -6.32677338e-02\n",
            "     1.93337415e-02]\n",
            "   [-3.80673778e-03 -1.77865656e-02 -3.73003269e-02 -9.50172900e-02\n",
            "     2.58125249e-02]\n",
            "   [ 4.86534124e-02  9.57980770e-02 -2.01010551e-02  3.98318775e-02\n",
            "     1.29319865e-02]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 6.31779739e-02  1.01060074e-01 -8.07149782e-03  9.04969194e-02\n",
            "    -5.79886610e-02]\n",
            "   [ 6.24990753e-02  3.15452051e-02  2.13318658e-02  1.91834085e-03\n",
            "    -1.63764509e-03]\n",
            "   [-2.87161458e-02 -2.82863728e-02  4.22685521e-02 -9.52511058e-02\n",
            "     8.78322131e-02]\n",
            "   [ 8.40275990e-02  2.91662544e-02  2.05043306e-02  2.42396597e-03\n",
            "     3.69256684e-03]\n",
            "   [ 4.71970129e-03 -3.66737630e-03  3.00678218e-02 -5.69693715e-02\n",
            "     1.14868783e-02]]\n",
            "\n",
            "  [[-3.36748112e-02 -2.98349453e-02  5.99808430e-02 -1.35099257e-02\n",
            "    -5.57773517e-03]\n",
            "   [ 1.50707453e-02  6.67167563e-02  3.29795400e-02 -9.73957550e-02\n",
            "     1.87164986e-02]\n",
            "   [-1.77334612e-02 -6.08223774e-02 -1.89777379e-02 -1.21826321e-02\n",
            "     3.00300005e-02]\n",
            "   [ 9.62758558e-02 -4.80933452e-02 -7.76234727e-02 -4.89171304e-02\n",
            "    -2.69472511e-02]\n",
            "   [-8.80733441e-03 -5.72311232e-02 -1.24301332e-02 -2.57506465e-02\n",
            "     2.69157924e-02]]\n",
            "\n",
            "  [[ 5.41842320e-02  6.60069147e-02  1.62386259e-02  4.58117915e-02\n",
            "     3.42666224e-02]\n",
            "   [-4.85967331e-02 -1.62039887e-02  8.93209556e-02 -6.84142946e-02\n",
            "     1.13886083e-01]\n",
            "   [ 6.63945038e-02 -3.80441234e-02 -4.14142898e-03  2.68294192e-02\n",
            "    -1.81933551e-03]\n",
            "   [ 3.76635721e-02 -7.35512972e-02 -8.67814088e-02 -4.06581422e-02\n",
            "     2.14768052e-02]\n",
            "   [ 2.95285754e-02 -1.49824450e-02 -5.95887412e-02  1.03727904e-02\n",
            "     4.50474780e-04]]]]\n",
            "inputOfConvLayer= [[[0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.01176471 0.07058824 0.07058824 0.07058824 0.49411765 0.53333336\n",
            "   0.6862745  0.10196079 0.6509804  1.         0.96862745 0.49803922\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.11764706 0.14117648 0.36862746 0.6039216\n",
            "   0.6666667  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            "   0.88235295 0.6745098  0.99215686 0.9490196  0.7647059  0.2509804\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.19215687 0.93333334 0.99215686 0.99215686 0.99215686\n",
            "   0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.9843137\n",
            "   0.3647059  0.32156864 0.32156864 0.21960784 0.15294118 0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.07058824 0.85882354 0.99215686 0.99215686 0.99215686\n",
            "   0.99215686 0.99215686 0.7764706  0.7137255  0.96862745 0.94509804\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.3137255  0.6117647  0.41960785 0.99215686\n",
            "   0.99215686 0.8039216  0.04313726 0.         0.16862746 0.6039216\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.05490196 0.00392157 0.6039216\n",
            "   0.99215686 0.3529412  0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.54509807\n",
            "   0.99215686 0.74509805 0.00784314 0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.04313726\n",
            "   0.74509805 0.99215686 0.27450982 0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.13725491 0.94509804 0.88235295 0.627451   0.42352942 0.00392157\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.31764707 0.9411765  0.99215686 0.99215686 0.46666667\n",
            "   0.09803922 0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.1764706  0.7294118  0.99215686 0.99215686\n",
            "   0.5882353  0.10588235 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.0627451  0.3647059  0.9882353\n",
            "   0.99215686 0.73333335 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.9764706\n",
            "   0.99215686 0.9764706  0.2509804  0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.18039216 0.50980395 0.7176471  0.99215686\n",
            "   0.99215686 0.8117647  0.00784314 0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.15294118 0.5803922  0.8980392  0.99215686 0.99215686 0.99215686\n",
            "   0.98039216 0.7137255  0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.09411765 0.44705883\n",
            "   0.8666667  0.99215686 0.99215686 0.99215686 0.99215686 0.7882353\n",
            "   0.30588236 0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.09019608 0.25882354 0.8352941  0.99215686\n",
            "   0.99215686 0.99215686 0.99215686 0.7764706  0.31764707 0.00784314\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.07058824 0.67058825 0.85882354 0.99215686 0.99215686 0.99215686\n",
            "   0.99215686 0.7647059  0.3137255  0.03529412 0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.21568628 0.6745098\n",
            "   0.8862745  0.99215686 0.99215686 0.99215686 0.99215686 0.95686275\n",
            "   0.52156866 0.04313726 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.53333336 0.99215686\n",
            "   0.99215686 0.99215686 0.83137256 0.5294118  0.5176471  0.0627451\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]]]\n",
            "In Conv's forward\n",
            "outShapezeropadding= (32, 32)\n",
            "inputOfConvLayer= [[[0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.04374387 0.        ]\n",
            "  [0.         0.         0.00736349 ... 0.         0.09014974 0.        ]\n",
            "  ...\n",
            "  [0.         0.09453586 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.51283497 0.61102437 ... 0.         0.         0.        ]\n",
            "  [0.         0.35963716 0.32050355 ... 0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.1186732  0.         0.        ]\n",
            "  [0.         0.         0.02008381 ... 0.23490977 0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.38961091 0.77474069 ... 0.         0.         0.        ]\n",
            "  [0.         0.31622546 0.27157531 ... 0.         0.         0.        ]\n",
            "  [0.         0.16436808 0.         ... 0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.14977482 0.07018558 0.        ]\n",
            "  [0.         0.         0.07858971 ... 0.         0.09528806 0.        ]\n",
            "  ...\n",
            "  [0.         0.23719084 0.10723371 ... 0.         0.         0.        ]\n",
            "  [0.         0.00453542 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.14633899 0.19940035 ... 0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.36062873 0.21996778 0.        ]\n",
            "  [0.         0.         0.05924478 ... 0.42731249 0.05593604 0.        ]\n",
            "  ...\n",
            "  [0.         0.47930908 0.88444742 ... 0.         0.         0.        ]\n",
            "  [0.         0.22265136 0.60960183 ... 0.         0.         0.        ]\n",
            "  [0.         0.03841142 0.         ... 0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.35033996 0.21430371 0.        ]\n",
            "  [0.         0.         0.00945376 ... 0.71675927 0.27923175 0.        ]\n",
            "  ...\n",
            "  [0.         0.39387069 0.88727808 ... 0.         0.         0.        ]\n",
            "  [0.         0.28126683 0.61253579 ... 0.         0.         0.        ]\n",
            "  [0.         0.01509253 0.         ... 0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.4325911  0.3364185  0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.18487065 ... 0.         0.         0.        ]\n",
            "  [0.         0.11804419 0.37161938 ... 0.         0.         0.        ]\n",
            "  [0.         0.13893056 0.51439027 ... 0.         0.         0.        ]]]\n",
            "In Conv's forward\n",
            "outShapezeropadding= (14, 14)\n",
            "outShapezeropadding= (14, 14)\n",
            "outShapezeropadding= (14, 14)\n",
            "outShapezeropadding= (14, 14)\n",
            "outShapezeropadding= (14, 14)\n",
            "outShapezeropadding= (14, 14)\n",
            "inputOfConvLayer= [[[0.13079605 0.34851254 0.63251837 0.50714016 0.59917875]\n",
            "  [0.         0.03271798 0.39084057 0.54018927 0.56095753]\n",
            "  [0.05375896 0.         0.38156685 0.82217292 0.91422834]\n",
            "  [0.17720509 0.49492714 0.80745407 0.71431021 0.46049827]\n",
            "  [0.07465648 0.30131065 0.37919236 0.26888795 0.12118206]]\n",
            "\n",
            " [[0.03833144 0.32581457 0.56561273 0.5326616  0.2107567 ]\n",
            "  [0.6096592  0.58011132 0.68812227 0.65753932 0.47610325]\n",
            "  [0.26339951 0.19953929 0.25768217 0.48313703 0.37237832]\n",
            "  [0.         0.5294477  0.86788975 0.81040503 0.        ]\n",
            "  [0.44271857 0.84234153 0.7372995  0.16584903 0.        ]]\n",
            "\n",
            " [[0.25681757 0.29253206 0.         0.         0.        ]\n",
            "  [0.         0.3037687  0.7865762  0.56549377 0.36635586]\n",
            "  [0.09120547 0.40872602 0.55196018 0.1402298  0.        ]\n",
            "  [0.51085338 0.5363534  0.45762135 0.14821955 0.07570266]\n",
            "  [0.21290232 0.         0.50065158 0.48159342 0.12918773]]\n",
            "\n",
            " [[0.         0.4578693  0.63584828 0.76980409 0.57120111]\n",
            "  [0.05216876 0.18292273 0.55019207 0.68128621 0.22979553]\n",
            "  [0.10998826 0.46030298 0.49043234 0.62881843 0.21207898]\n",
            "  [0.         0.27810654 0.75763514 0.91083189 0.26575695]\n",
            "  [0.29562113 0.67036879 0.61264044 0.42311059 0.23622808]]\n",
            "\n",
            " [[0.09897437 0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.20299836 0.19463785]\n",
            "  [0.         0.         0.         0.10219519 0.        ]\n",
            "  [0.         0.         0.         0.         0.        ]]\n",
            "\n",
            " [[0.08324559 0.07995815 0.         0.         0.        ]\n",
            "  [0.34400781 0.71555388 1.24354904 1.00620045 0.59692568]\n",
            "  [0.49160567 0.79107269 0.95545841 0.56239335 0.03995088]\n",
            "  [0.52188341 0.69947815 0.22852883 0.06754004 0.22638039]\n",
            "  [0.         0.36618589 0.64994701 0.70973844 0.60652518]]\n",
            "\n",
            " [[0.16357743 0.         0.16613857 0.32798242 0.38326416]\n",
            "  [0.         0.28872736 0.26494442 0.41454498 0.47196575]\n",
            "  [0.21433457 0.13839039 0.32056597 0.24615846 0.28165636]\n",
            "  [0.21692936 0.         0.         0.77196597 0.76770651]\n",
            "  [0.         0.05240471 0.72058839 0.84820388 0.49931516]]\n",
            "\n",
            " [[0.03419208 0.         0.         0.         0.        ]\n",
            "  [0.25643046 0.29024514 0.         0.         0.        ]\n",
            "  [0.19890511 0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.        ]\n",
            "  [0.21257334 0.         0.         0.         0.        ]]\n",
            "\n",
            " [[0.38412091 0.30504395 0.44437504 0.43141474 0.27327351]\n",
            "  [0.48406886 0.64633557 0.51794465 0.83765731 0.58153808]\n",
            "  [0.50573784 0.89473964 0.80927286 0.49478447 0.35839405]\n",
            "  [0.52933809 0.80207122 0.51744946 0.45639882 0.39391077]\n",
            "  [0.3263172  0.63328497 0.72048962 0.61285718 0.32273346]]\n",
            "\n",
            " [[0.19956138 0.69768628 1.10356398 0.89349356 0.71431015]\n",
            "  [0.53069921 1.03799336 1.54476085 1.344315   0.8173808 ]\n",
            "  [0.11606531 0.52515644 0.91576965 0.93846225 0.50602344]\n",
            "  [0.16988366 0.80097566 1.358574   1.4121126  0.76701097]\n",
            "  [0.73961174 1.12143206 1.31852089 0.62431312 0.39784647]]\n",
            "\n",
            " [[0.         0.         0.         0.01524627 0.0878509 ]\n",
            "  [0.3368714  0.32062376 0.41516811 0.48586953 0.31595387]\n",
            "  [0.33642532 0.48123728 0.13662779 0.         0.13692543]\n",
            "  [0.         0.         0.20452838 0.23237236 0.05468111]\n",
            "  [0.         0.11276301 0.65577921 0.41542471 0.22021208]]\n",
            "\n",
            " [[0.02709321 0.         0.08752945 0.0506735  0.16443167]\n",
            "  [0.         0.         0.         0.         0.        ]\n",
            "  [0.         0.1225638  0.01178947 0.22533273 0.26539526]\n",
            "  [0.31756697 0.16168267 0.         0.         0.21811959]\n",
            "  [0.         0.         0.         0.         0.14610824]]\n",
            "\n",
            " [[0.41796288 0.38258709 0.50553785 0.69097146 0.40494022]\n",
            "  [0.08989135 0.2269754  0.51559493 0.32832684 0.1767975 ]\n",
            "  [0.27020094 0.40432079 0.59317423 0.0630114  0.29423564]\n",
            "  [0.01085962 0.2014619  0.59604759 0.59972943 0.45216902]\n",
            "  [0.45328438 0.44857551 0.19360079 0.4736915  0.22679486]]\n",
            "\n",
            " [[0.48045524 0.32092924 0.         0.         0.0031121 ]\n",
            "  [0.61105213 0.54948909 0.         0.         0.        ]\n",
            "  [0.60336369 0.65482957 0.109926   0.         0.        ]\n",
            "  [0.13429801 0.         0.         0.         0.        ]\n",
            "  [0.42320638 0.37079032 0.27677265 0.14637376 0.        ]]\n",
            "\n",
            " [[0.         0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.27760602]\n",
            "  [0.1443735  0.08248587 0.         0.         0.1139364 ]\n",
            "  [0.         0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.09309417 0.        ]]\n",
            "\n",
            " [[0.         0.         0.         0.         0.        ]\n",
            "  [0.00430896 0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.35456484]\n",
            "  [0.         0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.02193236]]]\n",
            "In Conv's forward\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "inputOfConvLayer= [[[0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.2        0.62352943 0.99215686\n",
            "   0.62352943 0.19607843 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.1882353  0.93333334 0.9882353  0.9882353\n",
            "   0.9882353  0.92941177 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.21176471 0.8901961  0.99215686 0.9882353  0.9372549\n",
            "   0.9137255  0.9882353  0.22352941 0.02352941 0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.03921569\n",
            "   0.23529412 0.8784314  0.9882353  0.99215686 0.9882353  0.7921569\n",
            "   0.32941177 0.9882353  0.99215686 0.47843137 0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.6392157\n",
            "   0.9882353  0.9882353  0.9882353  0.99215686 0.9882353  0.9882353\n",
            "   0.3764706  0.7411765  0.99215686 0.654902   0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.2        0.93333334\n",
            "   0.99215686 0.99215686 0.74509805 0.44705883 0.99215686 0.89411765\n",
            "   0.18431373 0.30980393 1.         0.65882355 0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.1882353  0.93333334 0.9882353\n",
            "   0.9882353  0.7019608  0.04705882 0.29411766 0.4745098  0.08235294\n",
            "   0.         0.         0.99215686 0.9529412  0.19607843 0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.14901961 0.64705884 0.99215686 0.9137255\n",
            "   0.8156863  0.32941177 0.         0.         0.         0.\n",
            "   0.         0.         0.99215686 0.9882353  0.64705884 0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.02745098 0.69803923 0.9882353  0.9411765  0.2784314\n",
            "   0.07450981 0.10980392 0.         0.         0.         0.\n",
            "   0.         0.         0.99215686 0.9882353  0.7647059  0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.22352941 0.9882353  0.9882353  0.24705882 0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.99215686 0.9882353  0.7647059  0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.7764706  0.99215686 0.74509805 0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         1.         0.99215686 0.76862746 0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.29803923 0.9647059  0.9882353  0.4392157  0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.99215686 0.9882353  0.5803922  0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.33333334 0.9882353  0.9019608  0.09803922 0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.02745098 0.5294118  0.99215686 0.7294118  0.04705882 0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.33333334 0.9882353  0.8745098  0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.02745098\n",
            "   0.5137255  0.9882353  0.88235295 0.2784314  0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.33333334 0.9882353  0.5686275  0.         0.         0.\n",
            "   0.         0.         0.         0.         0.1882353  0.64705884\n",
            "   0.9882353  0.6784314  0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.3372549  0.99215686 0.88235295 0.         0.         0.\n",
            "   0.         0.         0.         0.44705883 0.93333334 0.99215686\n",
            "   0.63529414 0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.33333334 0.9882353  0.9764706  0.57254905 0.1882353  0.11372549\n",
            "   0.33333334 0.69803923 0.88235295 0.99215686 0.8745098  0.654902\n",
            "   0.21960784 0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.33333334 0.9882353  0.9882353  0.9882353  0.8980392  0.84313726\n",
            "   0.9882353  0.9882353  0.9882353  0.76862746 0.50980395 0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.10980392 0.78039217 0.9882353  0.9882353  0.99215686 0.9882353\n",
            "   0.9882353  0.9137255  0.5686275  0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.09803922 0.5019608  0.9882353  0.99215686 0.9882353\n",
            "   0.5529412  0.14509805 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]]]\n",
            "In Conv's forward\n",
            "outShapezeropadding= (32, 32)\n",
            "inputOfConvLayer= [[[1.52460440e-04 1.52460440e-04 1.52460440e-04 ... 1.52460440e-04\n",
            "   1.52460440e-04 1.52460440e-04]\n",
            "  [1.52460440e-04 1.52460440e-04 1.52460440e-04 ... 1.52460440e-04\n",
            "   1.52460440e-04 1.52460440e-04]\n",
            "  [1.52460440e-04 1.52460440e-04 1.52460440e-04 ... 4.31838733e-02\n",
            "   1.52460440e-04 1.52460440e-04]\n",
            "  ...\n",
            "  [1.52460440e-04 1.52460440e-04 5.16080370e-01 ... 1.52460440e-04\n",
            "   1.52460440e-04 1.52460440e-04]\n",
            "  [1.52460440e-04 1.52460440e-04 3.34048562e-01 ... 1.52460440e-04\n",
            "   1.52460440e-04 1.52460440e-04]\n",
            "  [1.52460440e-04 1.52460440e-04 1.52460440e-04 ... 1.52460440e-04\n",
            "   1.52460440e-04 1.52460440e-04]]\n",
            "\n",
            " [[1.49828865e-04 1.49828865e-04 1.49828865e-04 ... 1.49828865e-04\n",
            "   1.49828865e-04 1.49828865e-04]\n",
            "  [1.49828865e-04 1.49828865e-04 1.49828865e-04 ... 1.49828865e-04\n",
            "   1.49828865e-04 1.49828865e-04]\n",
            "  [1.49828865e-04 1.49828865e-04 1.49828865e-04 ... 0.00000000e+00\n",
            "   1.49828865e-04 1.49828865e-04]\n",
            "  ...\n",
            "  [1.49828865e-04 1.49828865e-04 4.84476289e-01 ... 1.49828865e-04\n",
            "   1.49828865e-04 1.49828865e-04]\n",
            "  [1.49828865e-04 1.49828865e-04 2.07500544e-01 ... 1.49828865e-04\n",
            "   1.49828865e-04 1.49828865e-04]\n",
            "  [1.49828865e-04 1.49828865e-04 1.49828865e-04 ... 1.49828865e-04\n",
            "   1.49828865e-04 1.49828865e-04]]\n",
            "\n",
            " [[5.48404156e-05 5.48404156e-05 5.48404156e-05 ... 5.48404156e-05\n",
            "   5.48404156e-05 5.48404156e-05]\n",
            "  [5.48404156e-05 5.48404156e-05 5.48404156e-05 ... 5.48404156e-05\n",
            "   5.48404156e-05 5.48404156e-05]\n",
            "  [5.48404156e-05 5.48404156e-05 5.48404156e-05 ... 9.81632980e-02\n",
            "   5.48404156e-05 5.48404156e-05]\n",
            "  ...\n",
            "  [5.48404156e-05 5.48404156e-05 2.07128238e-02 ... 5.48404156e-05\n",
            "   5.48404156e-05 5.48404156e-05]\n",
            "  [5.48404156e-05 5.48404156e-05 8.25429717e-02 ... 5.48404156e-05\n",
            "   5.48404156e-05 5.48404156e-05]\n",
            "  [5.48404156e-05 5.48404156e-05 5.48404156e-05 ... 5.48404156e-05\n",
            "   5.48404156e-05 5.48404156e-05]]\n",
            "\n",
            " [[4.03800901e-04 4.03800901e-04 4.03800901e-04 ... 4.03800901e-04\n",
            "   4.03800901e-04 4.03800901e-04]\n",
            "  [4.03800901e-04 4.03800901e-04 4.03800901e-04 ... 4.03800901e-04\n",
            "   4.03800901e-04 4.03800901e-04]\n",
            "  [4.03800901e-04 4.03800901e-04 4.03800901e-04 ... 1.53791116e-01\n",
            "   4.03800901e-04 4.03800901e-04]\n",
            "  ...\n",
            "  [4.03800901e-04 4.03800901e-04 2.66567648e-01 ... 4.03800901e-04\n",
            "   4.03800901e-04 4.03800901e-04]\n",
            "  [4.03800901e-04 4.03800901e-04 4.96821288e-02 ... 4.03800901e-04\n",
            "   4.03800901e-04 4.03800901e-04]\n",
            "  [4.03800901e-04 4.03800901e-04 4.03800901e-04 ... 4.03800901e-04\n",
            "   4.03800901e-04 4.03800901e-04]]\n",
            "\n",
            " [[4.47675593e-05 4.47675593e-05 4.47675593e-05 ... 4.47675593e-05\n",
            "   4.47675593e-05 4.47675593e-05]\n",
            "  [4.47675593e-05 4.47675593e-05 4.47675593e-05 ... 4.47675593e-05\n",
            "   4.47675593e-05 4.47675593e-05]\n",
            "  [4.47675593e-05 4.47675593e-05 4.47675593e-05 ... 2.23775158e-01\n",
            "   4.47675593e-05 4.47675593e-05]\n",
            "  ...\n",
            "  [4.47675593e-05 4.47675593e-05 2.60849678e-01 ... 4.47675593e-05\n",
            "   4.47675593e-05 4.47675593e-05]\n",
            "  [4.47675593e-05 4.47675593e-05 2.24643015e-02 ... 4.47675593e-05\n",
            "   4.47675593e-05 4.47675593e-05]\n",
            "  [4.47675593e-05 4.47675593e-05 4.47675593e-05 ... 4.47675593e-05\n",
            "   4.47675593e-05 4.47675593e-05]]\n",
            "\n",
            " [[3.73442931e-04 3.73442931e-04 3.73442931e-04 ... 3.73442931e-04\n",
            "   3.73442931e-04 3.73442931e-04]\n",
            "  [3.73442931e-04 3.73442931e-04 3.73442931e-04 ... 3.73442931e-04\n",
            "   3.73442931e-04 3.73442931e-04]\n",
            "  [3.73442931e-04 3.73442931e-04 3.73442931e-04 ... 1.05584494e-02\n",
            "   3.73442931e-04 3.73442931e-04]\n",
            "  ...\n",
            "  [3.73442931e-04 3.73442931e-04 1.80345783e-01 ... 3.73442931e-04\n",
            "   3.73442931e-04 3.73442931e-04]\n",
            "  [3.73442931e-04 3.73442931e-04 5.61521582e-02 ... 3.73442931e-04\n",
            "   3.73442931e-04 3.73442931e-04]\n",
            "  [3.73442931e-04 3.73442931e-04 3.73442931e-04 ... 3.73442931e-04\n",
            "   3.73442931e-04 3.73442931e-04]]]\n",
            "In Conv's forward\n",
            "outShapezeropadding= (14, 14)\n",
            "outShapezeropadding= (14, 14)\n",
            "outShapezeropadding= (14, 14)\n",
            "outShapezeropadding= (14, 14)\n",
            "outShapezeropadding= (14, 14)\n",
            "outShapezeropadding= (14, 14)\n",
            "inputOfConvLayer= [[[0.         0.23260172 0.60203528 0.55289661 0.7718039 ]\n",
            "  [0.02606316 0.34048696 0.19382643 0.49208618 0.60936897]\n",
            "  [0.09985231 0.23823542 0.09065039 0.66736554 0.54331633]\n",
            "  [0.08825265 0.3793605  0.6014614  0.43246854 0.3219245 ]\n",
            "  [0.07127676 0.         0.40002107 0.1737407  0.15582858]]\n",
            "\n",
            " [[0.         0.44933405 1.00779225 0.39697464 0.49021747]\n",
            "  [0.29064588 1.3690815  1.05984857 0.         0.34787982]\n",
            "  [0.65561746 1.0010712  0.         1.06041783 0.67822827]\n",
            "  [0.46608034 0.13673216 0.91830684 0.91496094 0.32525164]\n",
            "  [0.53815902 0.60487351 0.48465381 0.4770602  0.01777036]]\n",
            "\n",
            " [[0.18167345 0.48818105 0.22371433 0.00243283 0.07419993]\n",
            "  [0.30449978 0.06635097 0.40720132 0.60392481 0.51106013]\n",
            "  [0.269334   0.58757789 0.52380677 0.48969655 0.2813963 ]\n",
            "  [0.58541808 0.5814928  0.15851016 0.08259151 0.19712637]\n",
            "  [0.2573285  0.         0.4477433  0.29790517 0.17513125]]\n",
            "\n",
            " [[0.         0.07221364 0.54704695 0.7849833  0.52867722]\n",
            "  [0.         0.5608918  0.71926387 0.5195797  0.65600311]\n",
            "  [0.44784844 0.64768758 0.34747088 0.2702868  0.69682073]\n",
            "  [0.63305631 0.57735342 0.49670471 0.65438933 0.545815  ]\n",
            "  [0.49843959 0.68645945 0.63092143 0.29658366 0.14496054]]\n",
            "\n",
            " [[0.01392622 0.         0.29992729 0.33633614 0.        ]\n",
            "  [0.         0.         0.         0.         0.00747947]\n",
            "  [0.         0.         0.         0.         0.11616499]\n",
            "  [0.         0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.        ]]\n",
            "\n",
            " [[0.29992039 0.28421256 0.         0.         0.04892764]\n",
            "  [0.20992579 0.38966893 0.62827177 0.90135375 0.97807166]\n",
            "  [0.58500312 0.87730055 0.87285906 0.98510726 0.60880273]\n",
            "  [0.86270931 0.97689188 0.36844358 0.20338135 0.39374441]\n",
            "  [0.37642978 0.6049681  0.83743636 0.55689274 0.47841803]]\n",
            "\n",
            " [[0.27889995 0.02108654 0.02926774 0.77104198 0.30394285]\n",
            "  [0.06304726 0.         0.97012005 0.96081258 0.34207317]\n",
            "  [0.         1.08632912 0.86287693 0.         0.94562149]\n",
            "  [0.         0.65729268 0.         0.02950572 0.8306903 ]\n",
            "  [0.         0.39079482 0.62074089 0.75140444 0.59645337]]\n",
            "\n",
            " [[0.         0.         0.         0.         0.        ]\n",
            "  [0.04497723 0.         0.         0.         0.        ]\n",
            "  [0.07625714 0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.        ]\n",
            "  [0.24160164 0.16053774 0.         0.         0.        ]]\n",
            "\n",
            " [[0.46814855 0.48656824 0.33215628 0.48729393 0.30388825]\n",
            "  [0.45061425 0.26680961 1.01793883 1.18626327 0.15615463]\n",
            "  [0.38170096 0.73375183 1.31674478 1.28414999 0.46883971]\n",
            "  [0.53907698 1.06107103 0.6841261  0.68529165 0.67168572]\n",
            "  [0.36286774 0.56040879 0.52698183 0.53091023 0.4918271 ]]\n",
            "\n",
            " [[0.0790029  0.64257751 1.56634605 1.2887909  1.02486028]\n",
            "  [0.51205562 1.39152293 1.48173508 1.28608285 1.02645884]\n",
            "  [0.81636691 1.12644306 0.76339249 1.02077999 0.85834399]\n",
            "  [0.72437026 0.93126587 0.91445289 1.04658998 0.7429741 ]\n",
            "  [0.69326809 1.05153618 1.08692923 0.67591113 0.30939136]]\n",
            "\n",
            " [[0.         0.         0.20772227 0.         0.0383839 ]\n",
            "  [0.         0.23310714 0.57450343 0.24847644 0.        ]\n",
            "  [0.         0.36221514 0.55131981 0.04785856 0.35253834]\n",
            "  [0.13191928 0.13949628 0.         0.26800441 0.43794199]\n",
            "  [0.20673919 0.09823436 0.43607286 0.44102906 0.25607419]]\n",
            "\n",
            " [[0.22663548 0.27312267 0.         0.         0.35906279]\n",
            "  [0.14580282 0.         0.         0.30736936 0.30673191]\n",
            "  [0.         0.         0.25906269 0.0601424  0.        ]\n",
            "  [0.         0.50442978 0.27386737 0.         0.0308415 ]\n",
            "  [0.         0.         0.         0.         0.056349  ]]\n",
            "\n",
            " [[0.17522252 0.2852007  0.29044713 0.45466171 0.30662509]\n",
            "  [0.29223404 0.09394195 0.43790203 0.62227292 0.32300233]\n",
            "  [0.35606876 0.35765964 0.47228801 0.41653878 0.56636807]\n",
            "  [0.26072471 0.64702962 0.54692397 0.2290684  0.44511696]\n",
            "  [0.42879172 0.57130477 0.29227716 0.36013537 0.30378021]]\n",
            "\n",
            " [[0.18367978 0.07812995 0.         0.05525982 0.        ]\n",
            "  [0.16252757 0.         0.33361324 0.18844119 0.        ]\n",
            "  [0.31340493 0.02105159 0.05513336 0.         0.        ]\n",
            "  [0.5125733  0.         0.         0.         0.        ]\n",
            "  [0.50263798 0.23686493 0.1235158  0.27783932 0.        ]]\n",
            "\n",
            " [[0.         0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.11319419 0.         0.        ]\n",
            "  [0.         0.1949879  0.15334638 0.19862752 0.18678662]\n",
            "  [0.         0.         0.         0.29003697 0.20377502]\n",
            "  [0.31416087 0.         0.         0.05650769 0.02013403]]\n",
            "\n",
            " [[0.         0.06677076 0.         0.         0.16068124]\n",
            "  [0.08779193 0.03799836 0.         0.         0.        ]\n",
            "  [0.10743861 0.         0.06643225 0.         0.        ]\n",
            "  [0.         0.         0.4092002  0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.02961349]]]\n",
            "In Conv's forward\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "outShapezeropadding= (5, 5)\n",
            "inputOfConvLayer= [[[0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.2627451  0.9098039  0.15294118 0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.24313726 0.31764707\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.47058824 0.7058824  0.15294118 0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.49411765 0.6392157\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.00784314 0.6        0.8235294  0.15686275 0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.8627451  0.6392157\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.10588235 0.99607843 0.63529414 0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.87058824 0.6392157\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.7176471  0.99607843 0.49019608 0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.18039216 0.9607843  0.6392157\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.7764706  0.99607843 0.21960784 0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.47058824 0.99607843 0.6392157\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.09019608 0.90588236 0.99607843 0.11372549 0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.62352943 0.99607843 0.47058824\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.6392157  0.99607843 0.84705883 0.0627451  0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.62352943 0.99607843 0.2627451\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.05490196 0.3372549  0.69803923\n",
            "   0.972549   0.99607843 0.35686275 0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.62352943 0.99607843 0.33333334\n",
            "   0.         0.         0.         0.18431373 0.19215687 0.45490196\n",
            "   0.5647059  0.5882353  0.94509804 0.9529412  0.91764706 0.7019608\n",
            "   0.94509804 0.9882353  0.15686275 0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.5882353  0.99215686 0.92941177\n",
            "   0.8117647  0.8117647  0.8117647  0.99215686 0.99607843 0.98039216\n",
            "   0.9411765  0.7764706  0.56078434 0.35686275 0.10980392 0.01960784\n",
            "   0.9137255  0.98039216 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.46666667 0.69411767\n",
            "   0.69411767 0.69411767 0.69411767 0.69411767 0.38431373 0.21960784\n",
            "   0.         0.         0.         0.         0.         0.4\n",
            "   0.99607843 0.8627451  0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.6627451\n",
            "   0.99607843 0.5372549  0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.6627451\n",
            "   0.99607843 0.22352941 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.6627451\n",
            "   0.99607843 0.22352941 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.6627451\n",
            "   1.         0.36862746 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.6627451\n",
            "   0.99607843 0.3764706  0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.6627451\n",
            "   0.99607843 0.6        0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.6627451\n",
            "   1.         0.6        0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.3764706\n",
            "   0.99607843 0.6        0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]]]\n",
            "In Conv's forward\n",
            "outShapezeropadding= (32, 32)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-073e5bc4876e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# print(\"shapexReshape=\",output.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m           \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m           \u001b[0;31m# print(\"forward\",layer, \"finish\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m           \u001b[0;31m# input(\"plz enter the word\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-4feabf5ee1fa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     95\u001b[0m                     \u001b[0mWeights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                     \u001b[0;31m# print(\"WeightShape=\",Weights.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                     \u001b[0mfeature_maps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m                     \u001b[0;31m# print(\"feature_mapsOfConvLayer=\",feature_maps)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# print(\"Lastfeature_mapsOfConvLayer=\",feature_maps.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# unlike the Medium article, I am not encapsulating this process in a separate class\n",
        "# I think it is nice just like this\n",
        "network = [\n",
        "    Convolution2D(1, 6, 5, 2, 1),\n",
        "    ActivationLayer(relu, relu_prime),\n",
        "    Maxpooling2D(2,2),\n",
        "    Convolution2D(6,16,5,0,1),\n",
        "    ActivationLayer(relu, relu_prime),\n",
        "    Maxpooling2D(2,2),\n",
        "    Convolution2D(16, 120,5,0,1),\n",
        "    FlattenLayer(120),\n",
        "    FCLayer(120, 84),\n",
        "    ActivationLayer(relu, relu_prime),\n",
        "    FCLayer(84, 10),\n",
        "    SoftmaxLayer(10)\n",
        "]\n",
        "\n",
        "epochs = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "# training\n",
        "for epoch in range(epochs):\n",
        "    error = 0\n",
        "    for x, y_true in zip(x_train, y_train):\n",
        "        # forward\n",
        "        # print(\"x=\",x)\n",
        "        # print(\"y_true=\",y_true)\n",
        "        # print(\"shapex=\",x.shape)\n",
        "        output = x.reshape((1,x.shape[0], x.shape[1]))\n",
        "        # print(\"xReshape=\",output)\n",
        "        # print(\"shapexReshape=\",output.shape)\n",
        "        for layer in network:\n",
        "          output = layer.forward(output)\n",
        "          # print(\"forward\",layer, \"finish\")\n",
        "          # input(\"plz enter the word\")\n",
        "        \n",
        "        # print(\"forward epoch\",epoch,\"finish\")\n",
        "        # error (display purpose only)\n",
        "        error += mse(y_true, output)\n",
        "\n",
        "        # backward\n",
        "        output_error = mse_prime(y_true, output)\n",
        "\n",
        "        for layer in reversed(network):\n",
        "            output_error = layer.backward(output_error, learning_rate)\n",
        "            # print(\"backward\",layer,\"finish\")\n",
        "            # input(\"plz enter the word\")\n",
        "\n",
        "\n",
        "            # print(\"output_errorShape=\",output_error.shape)\n",
        "            \n",
        "\n",
        "        # print(\"backward epoch\",epoch,\"finish\")\n",
        "        # input(\"plz enter the word\")\n",
        "\n",
        "    \n",
        "    error /= len(x_train)\n",
        "    print('%d/%d, error=%f' % (epoch + 1, epochs, error))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrMLx3eGv3jk"
      },
      "outputs": [],
      "source": [
        "def predict(network, input):\n",
        "    prediction=True\n",
        "    \n",
        "    x=input.reshape(1,input.shape[0],input.shape[1])\n",
        "    # print(\"shapereshape\",(input.reshape(1,input.shape[0],input.shape[1])).shape)\n",
        "    output = x\n",
        "    # print(\"inputShape\",input.shape)\n",
        "\n",
        "    # print(\"Prediction In Test=\",prediction)\n",
        "\n",
        "    for layer in network:\n",
        "      print(\"layer.name\",layer) \n",
        "      if layer == network[0]:\n",
        "        output = layer.forwardStochastic(output)\n",
        "      elif layer == network[3]:\n",
        "        output = layer.forwardStochastic(output)\n",
        "      elif layer == network[6]:\n",
        "        output = layer.forwardStochastic(output)\n",
        "      else:\n",
        "        output = layer.forward(output)\n",
        "        # print(\"outputShape\",output.shape)\n",
        "    return output\n",
        "\n",
        "ratio = sum([np.argmax(y) == np.argmax(predict(network, x)) for x, y in zip(x_test, y_test)]) / len(x_test)\n",
        "error = sum([mse(y, predict(network, x)) for x, y in zip(x_test, y_test)]) / len(x_test)\n",
        "print('ratio: %.2f' % ratio)\n",
        "print('mse: %.4f' % error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERV5_QinvwXY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "samples = 10\n",
        "for test, true in zip(x_test[:samples], y_test[:samples]):\n",
        "    image = np.reshape(test, (28, 28))\n",
        "    plt.imshow(image, cmap='binary')\n",
        "    plt.show()\n",
        "    pred = predict(network, test)[0]\n",
        "    idx = np.argmax(pred)\n",
        "    idx_true = np.argmax(true)\n",
        "    print('pred: %s, prob: %.2f, true: %d' % (idx, pred[idx], idx_true))"
      ]
    }
  ]
}