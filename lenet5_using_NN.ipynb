{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatisepah/samples/blob/main/lenet5_using_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npFemIWusYQi"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Convolution2D:\n",
        "\n",
        "    def __init__(self, inputs_channel, num_filters, kernel_size, padding, stride):\n",
        "        # weight size: (F, C, K, K)\n",
        "        # bias size: (F) \n",
        "        self.F = num_filters\n",
        "        self.K = kernel_size\n",
        "        self.C = inputs_channel\n",
        "\n",
        "        self.weights = np.zeros((self.F, self.C, self.K, self.K))\n",
        "        self.bias = np.zeros((self.F, 1))\n",
        "        for i in range(0,self.F):\n",
        "            self.weights[i,:,:,:] = np.random.normal(loc=0, scale=np.sqrt(1./(self.C*self.K*self.K)), size=(self.C, self.K, self.K))\n",
        "\n",
        "        self.p = padding\n",
        "        self.s = stride\n",
        "\n",
        "        print(\"F(num_filters)ConvLayer=\",self.F)\n",
        "        print(\"K(kernel_size)ConvLayer=\",self.K)\n",
        "        print(\"C(inputs_channel)ConvLayer=\",self.C)\n",
        "\n",
        "    def zero_padding(self, inputs, size):\n",
        "        w, h = inputs.shape[0], inputs.shape[1]\n",
        "        new_w = 2 * size + w\n",
        "        new_h = 2 * size + h\n",
        "        out = np.zeros((new_w, new_h))\n",
        "        out[size:w+size, size:h+size] = inputs\n",
        "        \n",
        "        return out\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # input size: (C, W, H)\n",
        "        # output size: (N, F ,WW, HH)\n",
        "        # print(\"inputOfConvLayer=\",inputs)\n",
        "        print(\"inputShapeOfConvLayer=\",inputs.shape)\n",
        "\n",
        "        C = inputs.shape[0]\n",
        "        print(\"C-inputs.shape[0]=\",C)\n",
        "\n",
        "        W = inputs.shape[1]+2*self.p\n",
        "        print(\"W-inputs.shape[1]=\",W)\n",
        "\n",
        "        H = inputs.shape[2]+2*self.p\n",
        "        print(\"H-inputs.shape[2]=\",H)\n",
        "\n",
        "        self.inputs = np.zeros((C, W, H))\n",
        "        # print(\"self.inputsConv=\",self.inputs)\n",
        "\n",
        "        for c in range(inputs.shape[0]):\n",
        "            self.inputs[c,:,:] = self.zero_padding(inputs[c,:,:], self.p)\n",
        "        # print(\"OutZero_padding=\",self.inputs)\n",
        "\n",
        "        #############  \n",
        "        WW =int((W - self.K)/self.s + 1)\n",
        "        print(\"WW=\",WW)\n",
        "        ##########\n",
        "        HH = int((H - self.K)/self.s + 1)\n",
        "        print(\"HH=\",HH)\n",
        "\n",
        "        feature_maps = np.zeros((self.F, WW, HH))\n",
        "        # print(\"feature_mapsOfConvLayerzero=\",feature_maps)\n",
        "\n",
        "        for f in range(self.F):\n",
        "            for w in range(0, WW, self.s):\n",
        "                for h in range(0, HH, self.s):\n",
        "                    # print(\"SelectInputh=\",self.inputs[:,w:w+self.K,h:h+self.K])\n",
        "                    sel=self.inputs[:,w:w+self.K,h:h+self.K]\n",
        "                    # print(\"SelectInputShape=\",sel.shape)\n",
        "                    Weights=self.weights[f,:,:,:]\n",
        "                    # print(\"WeightShape=\",Weights.shape)\n",
        "                    feature_maps[f,w,h]=np.sum(self.inputs[:,w:w+self.K,h:h+self.K]*self.weights[f,:,:,:])+self.bias[f]\n",
        "                    # print(\"feature_mapsOfConvLayer=\",feature_maps)\n",
        "        # print(\"Lastfeature_mapsOfConvLayer=\",feature_maps)\n",
        "\n",
        "        return feature_maps\n",
        "    \n",
        "\n",
        "    def backward(self, dy):\n",
        "\n",
        "        C, W, H = self.inputs.shape\n",
        "        print(\"inputs.shape=\",self.inputs.shape)\n",
        "\n",
        "\n",
        "        dx = np.zeros(self.inputs.shape)\n",
        "        dw = np.zeros(self.weights.shape)\n",
        "        db = np.zeros(self.bias.shape)\n",
        "\n",
        "        F, W, H = dy.shape\n",
        "        for f in range(F):\n",
        "            for w in range(0, W, self.s):\n",
        "                for h in range(0, H, self.s):\n",
        "                    dw[f,:,:,:]+=dy[f,w,h]*self.inputs[:,w:w+self.K,h:h+self.K]\n",
        "                    dx[:,w:w+self.K,h:h+self.K]+=dy[f,w,h]*self.weights[f,:,:,:]\n",
        "\n",
        "        for f in range(F):\n",
        "            db[f] = np.sum(dy[f, :, :])\n",
        "\n",
        "        self.weights -= self.lr * dw\n",
        "        self.bias -= self.lr * db\n",
        "        return dx\n",
        "\n",
        "    def extract(self):\n",
        "        return {self.name+'.weights':self.weights, self.name+'.bias':self.bias}\n",
        "\n",
        "    def feed(self, weights, bias):\n",
        "        self.weights = weights\n",
        "        self.bias = bias"
      ],
      "metadata": {
        "id": "Z9YCSRwH0MbL"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Maxpooling2D:\n",
        "\n",
        "    def __init__(self, pool_size, stride):\n",
        "        self.pool = pool_size\n",
        "        self.s = stride\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        C, W, H = inputs.shape\n",
        "        new_width =int((W - self.pool)/self.s + 1)\n",
        "        new_height = int((H - self.pool)/self.s + 1)\n",
        "        out = np.zeros((C, new_width, new_height))\n",
        "        for c in range(C):\n",
        "            for w in range(W/self.s):\n",
        "                for h in range(H/self.s):\n",
        "                    out[c, w, h] = np.max(self.inputs[c, w*self.s:w*self.s+self.pool, h*self.s:h*self.s+self.pool])\n",
        "        return out\n",
        "\n",
        "    def backward(self, dy):\n",
        "        C, W, H = self.inputs.shape\n",
        "        dx = np.zeros(self.inputs.shape)\n",
        "        \n",
        "        for c in range(C):\n",
        "            for w in range(0, W, self.pool):\n",
        "                for h in range(0, H, self.pool):\n",
        "                    st = np.argmax(self.inputs[c,w:w+self.pool,h:h+self.pool])\n",
        "                    (idx, idy) = np.unravel_index(st, (self.pool, self.pool))\n",
        "                    dx[c, w+idx, h+idy] = dy[c, w/self.pool, h/self.pool]\n",
        "        return dx\n",
        "\n",
        "    def extract(self):\n",
        "        return "
      ],
      "metadata": {
        "id": "uhZYbVwxtd7c"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTrTMpTwtLXd"
      },
      "source": [
        "class FCLayer:\n",
        "    def __init__(self, input_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.weights = np.random.randn(input_size, output_size) / np.sqrt(input_size + output_size)\n",
        "        self.bias = np.random.randn(1, output_size) / np.sqrt(input_size + output_size)\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        return np.dot(input, self.weights) + self.bias\n",
        "\n",
        "    def backward(self, output_error, learning_rate):\n",
        "        input_error = np.dot(output_error, self.weights.T)\n",
        "        weights_error = np.dot(self.input.T, output_error)\n",
        "        # bias_error = output_error\n",
        "        \n",
        "        self.weights -= learning_rate * weights_error\n",
        "        self.bias -= learning_rate * output_error\n",
        "        return input_error"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6nSYAB2sam3"
      },
      "source": [
        "class ActivationLayer:\n",
        "    def __init__(self, activation, activation_prime):\n",
        "        self.activation = activation\n",
        "        self.activation_prime = activation_prime\n",
        "    \n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        return self.activation(input)\n",
        "    \n",
        "    def backward(self, output_error, learning_rate):\n",
        "        return output_error * self.activation_prime(self.input)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl8LxP1lAEiN"
      },
      "source": [
        "# bonus\n",
        "class FlattenLayer:\n",
        "    def __init__(self, input_shape):\n",
        "        self.input_shape = input_shape\n",
        "\n",
        "    def forward(self, input):\n",
        "        return np.reshape(input, (1, -1))\n",
        "    \n",
        "    def backward(self, output_error, learning_rate):\n",
        "        return np.reshape(output_error, self.input_shape)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Flatten:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def forward(self, inputs):\n",
        "        self.C, self.W, self.H = inputs.shape\n",
        "        return inputs.reshape(1, self.C*self.W*self.H)\n",
        "    def backward(self, dy):\n",
        "        return dy.reshape(self.C, self.W, self.H)\n",
        "    def extract(self):\n",
        "        return"
      ],
      "metadata": {
        "id": "PHs8z8hNyb49"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQeuIfkK3vyl"
      },
      "source": [
        "# bonus\n",
        "class SoftmaxLayer:\n",
        "    def __init__(self, input_size):\n",
        "        self.input_size = input_size\n",
        "    \n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        tmp = np.exp(input)\n",
        "        self.output = tmp / np.sum(tmp)\n",
        "        return self.output\n",
        "    \n",
        "    def backward(self, output_error, learning_rate):\n",
        "        input_error = np.zeros(output_error.shape)\n",
        "        out = np.tile(self.output.T, self.input_size)\n",
        "        return self.output * np.dot(output_error, np.identity(self.input_size) - out)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuPbn70Wt8Q7"
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_prime(x):\n",
        "    return np.exp(-x) / (1 + np.exp(-x))**2\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def tanh_prime(x):\n",
        "    return 1 - np.tanh(x)**2\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(x, 0)\n",
        "\n",
        "def relu_prime(x):\n",
        "    return np.array(x >= 0).astype('int')"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXY7jkUzuqEk"
      },
      "source": [
        "def mse(y_true, y_pred):\n",
        "    return np.mean(np.power(y_true - y_pred, 2))\n",
        "\n",
        "def mse_prime(y_true, y_pred):\n",
        "    return 2 * (y_pred - y_true) / y_pred.size\n",
        "\n",
        "def sse(y_true, y_pred):\n",
        "    return 0.5 * np.sum(np.power(y_true - y_pred, 2))\n",
        "\n",
        "def sse_prime(y_true, y_pred):\n",
        "    return y_pred - y_true"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-whGNp8Joaur"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_train /= 255\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "x_train = x_train[0:1000]\n",
        "y_train = y_train[0:1000]\n",
        "\n",
        "x_test = x_test.astype('float32')\n",
        "x_test /= 255\n",
        "y_test = np_utils.to_categorical(y_test)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHQpwN8LpKiN",
        "outputId": "fda122d4-82e5-4bb6-d386-31912008616f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        }
      },
      "source": [
        "# unlike the Medium article, I am not encapsulating this process in a separate class\n",
        "# I think it is nice just like this\n",
        "network = [\n",
        "    # FlattenLayer(input_shape=(1,32, 32)),\n",
        "    Convolution2D(1, 6, 5, 2, 1),\n",
        "    ActivationLayer(relu, relu_prime),\n",
        "    Maxpooling2D(2,2),\n",
        "    Convolution2D(6,16,5,0,1),\n",
        "    ActivationLayer(relu, relu_prime),\n",
        "    Maxpooling2D(2,2),\n",
        "    Convolution2D(16, 120,5,0,1),\n",
        "    FlattenLayer(120),\n",
        "    FCLayer(120, 84),\n",
        "    ActivationLayer(relu, relu_prime),\n",
        "    FCLayer(84, 10),\n",
        "    SoftmaxLayer(10)\n",
        "]\n",
        "\n",
        "epochs = 40\n",
        "learning_rate = 0.1\n",
        "\n",
        "# training\n",
        "for epoch in range(epochs):\n",
        "    error = 0\n",
        "    for x, y_true in zip(x_train, y_train):\n",
        "        # forward\n",
        "        # print(\"x=\",x)\n",
        "        print(\"y_true=\",y_true)\n",
        "        print(\"shapex=\",x.shape)\n",
        "        output = x.reshape((1,x.shape[0], x.shape[1]))\n",
        "        # print(\"xReshape=\",output)\n",
        "        print(\"shapexReshape=\",output.shape)\n",
        "        for layer in network:\n",
        "            output = layer.forward(output)\n",
        "            print(\"layeh tamom\")\n",
        "        \n",
        "        # error (display purpose only)\n",
        "        error += mse(y_true, output)\n",
        "\n",
        "        # backward\n",
        "        output_error = mse_prime(y_true, output)\n",
        "        for layer in reversed(network):\n",
        "            output_error = layer.backward(output_error, learning_rate)\n",
        "    \n",
        "    error /= len(x_train)\n",
        "    print('%d/%d, error=%f' % (epoch + 1, epochs, error))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F(num_filters)ConvLayer= 6\n",
            "K(kernel_size)ConvLayer= 5\n",
            "C(inputs_channel)ConvLayer= 1\n",
            "F(num_filters)ConvLayer= 16\n",
            "K(kernel_size)ConvLayer= 5\n",
            "C(inputs_channel)ConvLayer= 6\n",
            "F(num_filters)ConvLayer= 120\n",
            "K(kernel_size)ConvLayer= 5\n",
            "C(inputs_channel)ConvLayer= 16\n",
            "y_true= [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "shapex= (28, 28)\n",
            "shapexReshape= (1, 28, 28)\n",
            "inputShapeOfConvLayer= (1, 28, 28)\n",
            "C-inputs.shape[0]= 1\n",
            "W-inputs.shape[1]= 32\n",
            "H-inputs.shape[2]= 32\n",
            "WW= 28\n",
            "HH= 28\n",
            "layeh tamom\n",
            "layeh tamom\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-18a538965c36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shapexReshape=\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"layeh tamom\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-269023763762>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mnew_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mnew_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrMLx3eGv3jk"
      },
      "source": [
        "def predict(network, input):\n",
        "    output = input\n",
        "    for layer in network:\n",
        "        output = layer.forward(output)\n",
        "    return output\n",
        "\n",
        "ratio = sum([np.argmax(y) == np.argmax(predict(network, x)) for x, y in zip(x_test, y_test)]) / len(x_test)\n",
        "error = sum([mse(y, predict(network, x)) for x, y in zip(x_test, y_test)]) / len(x_test)\n",
        "print('ratio: %.2f' % ratio)\n",
        "print('mse: %.4f' % error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERV5_QinvwXY"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "samples = 10\n",
        "for test, true in zip(x_test[:samples], y_test[:samples]):\n",
        "    image = np.reshape(test, (28, 28))\n",
        "    plt.imshow(image, cmap='binary')\n",
        "    plt.show()\n",
        "    pred = predict(network, test)[0]\n",
        "    idx = np.argmax(pred)\n",
        "    idx_true = np.argmax(true)\n",
        "    print('pred: %s, prob: %.2f, true: %d' % (idx, pred[idx], idx_true))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}