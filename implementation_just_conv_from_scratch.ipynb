{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcfHGYAKOPM9T3m+eQhkrT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatisepah/samples/blob/main/implementation_just_conv_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "DsjizSWxngA-"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Convolution2D:\n",
        "\n",
        "    def __init__(self, inputs_channel, num_filters, kernel_size, padding, stride):\n",
        "        # weight size: (F, C, K, K)\n",
        "        # bias size: (F) \n",
        "        self.F = num_filters\n",
        "        self.K = kernel_size\n",
        "        self.C = inputs_channel\n",
        "\n",
        "        self.weights = np.zeros((self.F, self.C, self.K, self.K))\n",
        "        self.bias = np.zeros((self.F, 1))\n",
        "        for i in range(0,self.F):\n",
        "            self.weights[i,:,:,:] = np.random.normal(loc=0, scale=np.sqrt(1./(self.C*self.K*self.K)), size=(self.C, self.K, self.K))\n",
        "\n",
        "        self.p = padding\n",
        "        self.s = stride\n",
        "\n",
        "        print(\"F(num_filters)ConvLayer=\",self.F)\n",
        "        print(\"K(kernel_size)ConvLayer=\",self.K)\n",
        "        print(\"C(inputs_channel)ConvLayer=\",self.C)\n",
        "\n",
        "    def zero_padding(self, inputs, size):\n",
        "        w, h = inputs.shape[0], inputs.shape[1]\n",
        "        new_w = 2 * size + w\n",
        "        new_h = 2 * size + h\n",
        "        out = np.zeros((new_w, new_h))\n",
        "        out[size:w+size, size:h+size] = inputs\n",
        "        \n",
        "        return out\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # input size: (C, W, H)\n",
        "        # output size: (N, F ,WW, HH)\n",
        "        # print(\"inputOfConvLayer=\",inputs)\n",
        "        print(\"inputShapeOfConvLayer=\",inputs.shape)\n",
        "\n",
        "        C = inputs.shape[0]\n",
        "        print(\"C-inputs.shape[0]=\",C)\n",
        "\n",
        "        W = inputs.shape[1]+2*self.p\n",
        "        print(\"W-inputs.shape[1]=\",W)\n",
        "\n",
        "        H = inputs.shape[2]+2*self.p\n",
        "        print(\"H-inputs.shape[2]=\",H)\n",
        "\n",
        "        self.inputs = np.zeros((C, W, H))\n",
        "        # print(\"self.inputsConv=\",self.inputs)\n",
        "\n",
        "        for c in range(inputs.shape[0]):\n",
        "            self.inputs[c,:,:] = self.zero_padding(inputs[c,:,:], self.p)\n",
        "        # print(\"OutZero_padding=\",self.inputs)\n",
        "\n",
        "        #############  \n",
        "        WW =int((W - self.K)/self.s + 1)\n",
        "        print(\"WW=\",WW)\n",
        "        ##########\n",
        "        HH = int((H - self.K)/self.s + 1)\n",
        "        print(\"HH=\",HH)\n",
        "\n",
        "        feature_maps = np.zeros((self.F, WW, HH))\n",
        "        # print(\"feature_mapsOfConvLayerzero=\",feature_maps)\n",
        "\n",
        "        for f in range(self.F):\n",
        "            for w in range(0, WW, self.s):\n",
        "                for h in range(0, HH, self.s):\n",
        "                    # print(\"SelectInputh=\",self.inputs[:,w:w+self.K,h:h+self.K])\n",
        "                    sel=self.inputs[:,w:w+self.K,h:h+self.K]\n",
        "                    # print(\"SelectInputShape=\",sel.shape)\n",
        "                    Weights=self.weights[f,:,:,:]\n",
        "                    # print(\"WeightShape=\",Weights.shape)\n",
        "                    feature_maps[f,w,h]=np.sum(self.inputs[:,w:w+self.K,h:h+self.K]*self.weights[f,:,:,:])+self.bias[f]\n",
        "                    # print(\"feature_mapsOfConvLayer=\",feature_maps)\n",
        "        # print(\"Lastfeature_mapsOfConvLayer=\",feature_maps)\n",
        "\n",
        "        return feature_maps\n",
        "    \n",
        "\n",
        "    def backward(self, dy):\n",
        "\n",
        "        C, W, H = self.inputs.shape\n",
        "        print(\"inputs.shape=\",self.inputs.shape)\n",
        "\n",
        "\n",
        "        dx = np.zeros(self.inputs.shape)\n",
        "        dw = np.zeros(self.weights.shape)\n",
        "        db = np.zeros(self.bias.shape)\n",
        "\n",
        "        F, W, H = dy.shape\n",
        "        for f in range(F):\n",
        "            for w in range(0, W, self.s):\n",
        "                for h in range(0, H, self.s):\n",
        "                    dw[f,:,:,:]+=dy[f,w,h]*self.inputs[:,w:w+self.K,h:h+self.K]\n",
        "                    dx[:,w:w+self.K,h:h+self.K]+=dy[f,w,h]*self.weights[f,:,:,:]\n",
        "\n",
        "        for f in range(F):\n",
        "            db[f] = np.sum(dy[f, :, :])\n",
        "\n",
        "        self.weights -= self.lr * dw\n",
        "        self.bias -= self.lr * db\n",
        "        return dx\n",
        "\n",
        "    def extract(self):\n",
        "        return {self.name+'.weights':self.weights, self.name+'.bias':self.bias}\n",
        "\n",
        "    def feed(self, weights, bias):\n",
        "        self.weights = weights\n",
        "        self.bias = bias"
      ],
      "metadata": {
        "id": "98TxRbgqn0iz"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bonus\n",
        "class SoftmaxLayer:\n",
        "    def __init__(self, input_size):\n",
        "        self.input_size = input_size\n",
        "\n",
        "        print(\"input_sizeOfSoftmax=\",input_size)\n",
        "        \n",
        "    \n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        tmp = np.exp(input)\n",
        "        self.output = tmp / np.sum(tmp)\n",
        "\n",
        "        print(\"output_sizeOfSoftmaxForward=\",self.output)\n",
        "        return self.output\n",
        "    \n",
        "    def backward(self, output_error, learning_rate):\n",
        "        input_error = np.zeros(output_error.shape)\n",
        "        out = np.tile(self.output.T, self.input_size)\n",
        "        return self.output * np.dot(output_error, np.identity(self.input_size) - out)"
      ],
      "metadata": {
        "id": "xC5YXH2_pukj"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FCLayer:\n",
        "    def __init__(self, input_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.weights = np.random.randn(input_size, output_size) / np.sqrt(input_size + output_size)\n",
        "        self.bias = np.random.randn(1, output_size) / np.sqrt(input_size + output_size)\n",
        "\n",
        "        print(\"input_sizeOfFCLayer=\",input_size)\n",
        "        print(\"output_sizeOfFCLayer=\",output_size)\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        return np.dot(input, self.weights) + self.bias\n",
        "\n",
        "    def backward(self, output_error, learning_rate):\n",
        "        input_error = np.dot(output_error, self.weights.T)\n",
        "        weights_error = np.dot(self.input.T, output_error)\n",
        "        # bias_error = output_error\n",
        "        \n",
        "        self.weights -= learning_rate * weights_error\n",
        "        self.bias -= learning_rate * output_error\n",
        "        return input_error"
      ],
      "metadata": {
        "id": "m-ZnYVIFpxnT"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ActivationLayer:\n",
        "    def __init__(self, activation, activation_prime):\n",
        "        self.activation = activation\n",
        "        self.activation_prime = activation_prime\n",
        "    \n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        return self.activation(input)\n",
        "    \n",
        "    def backward(self, output_error, learning_rate):\n",
        "        return output_error * self.activation_prime(self.input)"
      ],
      "metadata": {
        "id": "y8BKZ7aOn3Rb"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bonus\n",
        "class FlattenLayer:\n",
        "    def __init__(self, input_shape):\n",
        "        self.input_shape = input_shape\n",
        "\n",
        "        print(\"input_shapeOfFlatten=\",input_shape)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return np.reshape(input, (1, -1))\n",
        "    \n",
        "    def backward(self, output_error, learning_rate):\n",
        "        return np.reshape(output_error, self.input_shape)"
      ],
      "metadata": {
        "id": "W4z_S4vap-Xq"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Flatten:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def forward(self, inputs):\n",
        "        self.C, self.W, self.H = inputs.shape\n",
        "        return inputs.reshape(1, self.C*self.W*self.H)\n",
        "    def backward(self, dy):\n",
        "        return dy.reshape(self.C, self.W, self.H)\n",
        "    def extract(self):\n",
        "        return"
      ],
      "metadata": {
        "id": "TI7pUW7pOn5Y"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_prime(x):\n",
        "    return np.exp(-x) / (1 + np.exp(-x))**2\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def tanh_prime(x):\n",
        "    return 1 - np.tanh(x)**2\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(x, 0)\n",
        "\n",
        "def relu_prime(x):\n",
        "    return np.array(x >= 0).astype('int')"
      ],
      "metadata": {
        "id": "XcXCqUGin95r"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(y_true, y_pred):\n",
        "    return np.mean(np.power(y_true - y_pred, 2))\n",
        "\n",
        "def mse_prime(y_true, y_pred):\n",
        "    return 2 * (y_pred - y_true) / y_pred.size\n",
        "\n",
        "def sse(y_true, y_pred):\n",
        "    return 0.5 * np.sum(np.power(y_true - y_pred, 2))\n",
        "\n",
        "def sse_prime(y_true, y_pred):\n",
        "    return y_pred - y_true"
      ],
      "metadata": {
        "id": "2ek5g9nToJAj"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_train /= 255\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "x_train = x_train[0:1000]\n",
        "y_train = y_train[0:1000]\n",
        "\n",
        "x_test = x_test.astype('float32')\n",
        "x_test /= 255\n",
        "y_test = np_utils.to_categorical(y_test)"
      ],
      "metadata": {
        "id": "W1y46hycoLKz"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from PIL import Image\n",
        "# unlike the Medium article, I am not encapsulating this process in a separate class\n",
        "# I think it is nice just like this\n",
        "network = [\n",
        "    \n",
        "    Convolution2D(1, 6, 5, 0, 1),\n",
        "    ActivationLayer(relu, relu_prime),\n",
        "\n",
        "]\n",
        "\n",
        "epochs = 40\n",
        "learning_rate = 0.1\n",
        "\n",
        "# training\n",
        "for epoch in range(epochs):\n",
        "    error = 0\n",
        "    for x, y_true in zip(x_train, y_train):\n",
        "        # forward\n",
        "\n",
        "        # print(\"x=\",x)\n",
        "        print(\"y_true=\",y_true)\n",
        "        print(\"shapex=\",x.shape)\n",
        "        output = x.reshape((1,x.shape[0], x.shape[1]))\n",
        "        # print(\"xReshape=\",output)\n",
        "        print(\"shapexReshape=\",output.shape)\n",
        "        # data = Image.fromarray(output)\n",
        "        # data.show()\n",
        "\n",
        "        for layer in network:\n",
        "            output = layer.forward(output)\n",
        "            \n",
        "            #print(\"outputOfLayer=\",output)\n",
        "            # data = Image.fromarray(output)\n",
        "            # data.show()\n",
        "        \n",
        "        # error (display purpose only)\n",
        "        error += mse(y_true, output)\n",
        "\n",
        "        # backward\n",
        "        output_error = mse_prime(y_true, output)\n",
        "        for layer in reversed(network):\n",
        "            output_error = layer.backward(output_error, learning_rate)\n",
        "    \n",
        "    error /= len(x_train)\n",
        "    print('%d/%d, error=%f' % (epoch + 1, epochs, error))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "PWQ39GozoOMr",
        "outputId": "d9214f97-1b9f-46e4-f8e2-c59e98ca1fde"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F(num_filters)ConvLayer= 6\n",
            "K(kernel_size)ConvLayer= 5\n",
            "C(inputs_channel)ConvLayer= 1\n",
            "y_true= [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "shapex= (28, 28)\n",
            "shapexReshape= (1, 28, 28)\n",
            "inputShapeOfConvLayer= (1, 28, 28)\n",
            "C-inputs.shape[0]= 1\n",
            "W-inputs.shape[1]= 28\n",
            "H-inputs.shape[2]= 28\n",
            "WW= 24\n",
            "HH= 24\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-e298a154b9db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# error (display purpose only)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0merror\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-86-646dd53a2805>\u001b[0m in \u001b[0;36mmse\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmse_prime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,) (6,24,24) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(network, input):\n",
        "    output = input\n",
        "    for layer in network:\n",
        "        output = layer.forward(output)\n",
        "    return output\n",
        "\n",
        "ratio = sum([np.argmax(y) == np.argmax(predict(network, x)) for x, y in zip(x_test, y_test)]) / len(x_test)\n",
        "error = sum([mse(y, predict(network, x)) for x, y in zip(x_test, y_test)]) / len(x_test)\n",
        "print('ratio: %.2f' % ratio)\n",
        "print('mse: %.4f' % error)"
      ],
      "metadata": {
        "id": "rdVEVBz7oUDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "samples = 10\n",
        "for test, true in zip(x_test[:samples], y_test[:samples]):\n",
        "    image = np.reshape(test, (28, 28))\n",
        "    plt.imshow(image, cmap='binary')\n",
        "    plt.show()\n",
        "    pred = predict(network, test)[0]\n",
        "    idx = np.argmax(pred)\n",
        "    idx_true = np.argmax(true)\n",
        "    print('pred: %s, prob: %.2f, true: %d' % (idx, pred[idx], idx_true))"
      ],
      "metadata": {
        "id": "xPcltUC3oU4b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}