{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlraFr8/+/15/8forO9uj4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatisepah/samples/blob/main/Lenet_Mid_Inference_WithoutPrint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22wlQIiEl0n6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "prediction=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKIpp6RbIOnA"
      },
      "outputs": [],
      "source": [
        "class Convolution2D:\n",
        "\n",
        "\n",
        "    def __init__(self, inputs_channel, num_filters, kernel_size, padding, stride):\n",
        "        # weight size: (F, C, K, K)\n",
        "        # bias size: (F) \n",
        "        self.F = num_filters\n",
        "        self.K = kernel_size\n",
        "        self.C = inputs_channel\n",
        "        \n",
        "        # print(\"FInConv=\",self.F)\n",
        "        # print(\"KInConv=\",self.K)\n",
        "        # print(\"CInConv=\",self.C)\n",
        "\n",
        "        # print(\"In Conv's Init\")\n",
        "\n",
        "\n",
        "        self.weights = np.zeros((self.F, self.C, self.K, self.K))\n",
        "        self.bias = np.zeros((self.F, 1))\n",
        "        for i in range(0,self.F):\n",
        "            self.weights[i,:,:,:] = np.random.normal(loc=0, scale=np.sqrt(1./(self.C*self.K*self.K)), size=(self.C, self.K, self.K))\n",
        "\n",
        "        if prediction == True:\n",
        "          for f in range(self.F):\n",
        "            for c in range(self.C):\n",
        "              for h in range(self.K):\n",
        "                for w in range(self.K):\n",
        "                  self.weights[f,c,h,w]=int(self.weights[f,c,h,w]*31)\n",
        "\n",
        "          self.weights=self.weights.astype(int)\n",
        "\n",
        "        # print(\"weightsShapeConvLayer=\",self.weights.shape)\n",
        "        # print(\"weightsConvLayer=\",self.weights)\n",
        "\n",
        "        self.p = padding\n",
        "        self.s = stride\n",
        "\n",
        "        # print(\"F(num_filters)ConvLayer=\",self.F)\n",
        "        # print(\"K(kernel_size)ConvLayer=\",self.K)\n",
        "        # print(\"C(inputs_channel)ConvLayer=\",self.C)\n",
        "\n",
        "    def zero_padding(self, inputs, size):\n",
        "        w, h = inputs.shape[0], inputs.shape[1]\n",
        "        new_w = 2 * size + w\n",
        "        new_h = 2 * size + h\n",
        "        out = np.zeros((new_w, new_h))\n",
        "        out[size:w+size, size:h+size] = inputs\n",
        "\n",
        "        \n",
        "\n",
        "        # print(\"outShapezeropadding=\",out.shape)\n",
        "        return out\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # input size: (C, W, H)\n",
        "        # output size: (N, F ,WW, HH)\n",
        "        # print(\"inputOfConvLayer=\",inputs)\n",
        "        # print(\"inputShapeOfConvLayer=\",inputs.shape)\n",
        "\n",
        "        # print(\"In Conv's forward\")\n",
        "\n",
        "\n",
        "        C = inputs.shape[0]\n",
        "        # print(\"C-inputs.shape[0]=\",C)\n",
        "\n",
        "        W = inputs.shape[1]+2*self.p\n",
        "        # print(\"W-inputs.shape[1]=\",W)\n",
        "\n",
        "        H = inputs.shape[2]+2*self.p\n",
        "        # print(\"H-inputs.shape[2]=\",H)\n",
        "\n",
        "        self.inputs = np.zeros((C, W, H))\n",
        "        # print(\"self.inputsConv=\",self.inputs)\n",
        "\n",
        "        for c in range(inputs.shape[0]):\n",
        "            self.inputs[c,:,:] = self.zero_padding(inputs[c,:,:], self.p)\n",
        "        # print(\"OutZero_padding=\",self.inputs)\n",
        "\n",
        "        #############  \n",
        "        WW =int((W - self.K)/self.s + 1)\n",
        "        # print(\"WW=\",WW)\n",
        "        ##########\n",
        "        HH = int((H - self.K)/self.s + 1)\n",
        "        # print(\"HH=\",HH)\n",
        "\n",
        "        feature_maps = np.zeros((self.F, WW, HH))\n",
        "        # print(\"feature_mapsOfConvLayerzero=\",feature_maps)\n",
        "\n",
        "        for f in range(self.F):\n",
        "            for w in range(0, WW, self.s):\n",
        "                for h in range(0, HH, self.s):\n",
        "                    # print(\"SelectInputh=\",self.inputs[:,w:w+self.K,h:h+self.K])\n",
        "                    sel=self.inputs[:,w:w+self.K,h:h+self.K]\n",
        "                    # print(\"SelectInputShape=\",sel.shape)\n",
        "                    Weights=self.weights[f,:,:,:]\n",
        "                    # print(\"WeightShape=\",Weights.shape)\n",
        "                    feature_maps[f,w,h]=np.sum(self.inputs[:,w:w+self.K,h:h+self.K]*self.weights[f,:,:,:])+self.bias[f]\n",
        "                    # print(\"feature_mapsOfConvLayer=\",feature_maps)\n",
        "        # print(\"Lastfeature_mapsOfConvLayer=\",feature_maps.shape)\n",
        "        # print(\"conv's forward is done\")\n",
        "\n",
        "        return feature_maps\n",
        "\n",
        "    def forwardStochastic(self, inputs):#Stochastic\n",
        "        # input size: (C, W, H)\n",
        "        # output size: (N, F ,WW, HH)\n",
        "        # print(\"inputOfConvLayer=\",inputs)\n",
        "        # print(\"inputShapeOfConvLayer=\",inputs.shape)\n",
        "\n",
        "        # print(\"In Conv's forwardStocahstic\")\n",
        "\n",
        "        C = inputs.shape[0]\n",
        "        W = inputs.shape[1]+2*self.p\n",
        "        H = inputs.shape[2]+2*self.p\n",
        "\n",
        "\n",
        "        self.weights=self.weights.astype(int)\n",
        "\n",
        "\n",
        "        XBit=5\n",
        "        QBit=2\n",
        "        QTZRange=2**QBit\n",
        "        sign=1\n",
        "        XYInputBuf=inputs.shape\n",
        "        # print(\"XYInputBuf\",inputs.shape)\n",
        "        XInputBuf= XYInputBuf[1]+2*self.p\n",
        "        YInputBuf= XYInputBuf[2]+2*self.p\n",
        "        # print(\"XInputBuf\",XInputBuf)\n",
        "        # print(\"YInputBuf\",YInputBuf)\n",
        "\n",
        "        #find dimention of weight buffer\n",
        "        XYWeightBuf=self.weights.shape\n",
        "        XWBuf= XYWeightBuf[2]\n",
        "        YWBuf= XYWeightBuf[3]\n",
        "        lenWeight=len(self.weights)\n",
        "\n",
        "        ArrayMulReshape=np.array([])\n",
        "        ListKeyWeight=[]\n",
        "        DicWeight={}\n",
        "        #/////////////////////////////////////////////////////////////////////////////////////////////////////\n",
        "        def DetectTheMidValueOfRange(WeightBuffer):\n",
        "        \n",
        "        \t#reshape WeightSortArray to 1-D\n",
        "        \tWeightBuffer1D=WeightBuffer.reshape(-1)\n",
        "        \tprint(\"WeightBuffer1D=\",WeightBuffer1D)\n",
        "        \tXWeightBuf1D=WeightBuffer1D.shape[0]\n",
        "        \n",
        "        \n",
        "            #changing value of weightBuffer with the mid value of each range\n",
        "        \ti=0\n",
        "        \twhile i<XWeightBuf1D:\n",
        "        \t\tif WeightBuffer1D[i]<0:\n",
        "        \t\t\tfor x in range(QTZRange):\n",
        "        \t\t\t\tNfirst=((-(x+1)/QTZRange)*(2**XBit))-1\n",
        "        \t\t\t\tNlast=((-(x/QTZRange)*(2**XBit))-1)\n",
        "        \n",
        "        \t\t\t\tif (WeightBuffer1D[i]>Nfirst) &  (WeightBuffer1D[i]<=Nlast):\n",
        "        \t\t\t\t\t#the mid value of each range\n",
        "        \t\t\t\t\tWeightBuffer1D[i]=(Nfirst+Nlast)/2\n",
        "        \t\t\t\t\tbreak\n",
        "        \t\telse:\n",
        "        \t\t\tfor x in range(QTZRange):\n",
        "        \t\t\t\tPfirst=((x/QTZRange)*(2**XBit))\n",
        "        \t\t\t\tPlast=((x+1)/QTZRange)*(2**XBit)\n",
        "        \n",
        "        \t\t\t\tif (WeightBuffer1D[i]>=Pfirst) &  (WeightBuffer1D[i]<Plast):\n",
        "        \t\t\t\t\t#the mid value of each range\n",
        "        \t\t\t\t\tWeightBuffer1D[i]=(Pfirst+Plast)/2\n",
        "        \t\t\t\t\tbreak\n",
        "        \t\ti+=1\n",
        "        \tprint(\"WB-DetectTheMidValueOfRange=\",WeightBuffer1D)\n",
        "        \treturn WeightBuffer1D\n",
        "        \n",
        "        #/////////////////////////////////////////////////////////////////////////////////////////////////////\n",
        "        \n",
        "        def UpDownCounter(Enable,x,IncDec):\n",
        "          IntX=int(x)\n",
        "          Enable=int(Enable)\n",
        "          \n",
        "          if Enable != 0:\n",
        "            if IntX == 1:\n",
        "              if IncDec == 1:\n",
        "                IntX=1\n",
        "              else:\n",
        "                IntX=-1\n",
        "            else:\n",
        "              IntX=0\n",
        "          else:\n",
        "            IntX=0\n",
        "          return IntX\n",
        "        #/////////////////////////////////////////////////////////////////////////////////////////////////////\n",
        "        def DownCounter(x):\n",
        "          x-=1\n",
        "          return x\n",
        "        #/////////////////////////////////////////////////////////////////////////////////////////////////////\n",
        "        \n",
        "        def BISC(In):\n",
        "          # print(\"InBISC\",In)\n",
        "          # print(\"TypeInBISC\",type(In))\n",
        "          LenSc= 2 ** XBit\n",
        "          \n",
        "          sc=np.array([])\n",
        "          for x in range(LenSc):\n",
        "            sc=np.append(sc,[0])\n",
        "            \n",
        "          for x in range(XBit):\n",
        "            i=(2 ** x)-1\n",
        "            while i<LenSc:\n",
        "              sc[i] = In[x]\n",
        "              i+= 2 ** (x+1)\n",
        "              \n",
        "          sc = np.flip(sc)\n",
        "          return sc\n",
        "          \n",
        "        #/////////////////////////////////////////////////////////////////////////////////////////////////////\n",
        "        def DecimalToBinary(num,XBit):\n",
        "          i = 0\n",
        "          bnum = []\n",
        "          Binary=''\n",
        "          while num!=0:\n",
        "            rem = num%2\n",
        "            bnum.insert(i, rem)\n",
        "            i = i+1\n",
        "            num = int(num/2)\n",
        "          i = i-1\n",
        "          while i>=0:\n",
        "            Binary=Binary+str(bnum[i])\n",
        "            i = i-1\n",
        "          \n",
        "          while len(Binary)<XBit:\n",
        "            Binary='0'+Binary\n",
        "          # print(\"Binary:\",Binary)\n",
        "          \n",
        "          return Binary\n",
        "        #/////////////////////////////////////////////////////////////////////////////////////////////////////\n",
        "        def GetDefferentialWArray(w):\n",
        "          DifferentialWArray=np.array([])\n",
        "          \n",
        "          #sort weight 1-D\n",
        "          WeightSortArray1D=np.sort(w)\n",
        "          # print(\"WeightSortArray1D=\",WeightSortArray1D)\n",
        "          \n",
        "          #create sorted weight array based on Differential of weights\n",
        "          \n",
        "          DifferentialWArray=np.append(DifferentialWArray,WeightSortArray1D[0])\n",
        "          for x in range((XWBuf*YWBuf)-1):\n",
        "            Differential=WeightSortArray1D[x+1]-WeightSortArray1D[x]\n",
        "            DifferentialWArray=np.append(DifferentialWArray,Differential)\n",
        "          # print(\"DifferentialWArray=\",DifferentialWArray)\n",
        "          \n",
        "          return DifferentialWArray\n",
        "          \n",
        "        #/////////////////////////////////////////////////////////////////////////////////////////////////////\n",
        "        \n",
        "        def SortDicIndexWeight(w):\n",
        "          w=np.reshape(w,(XWBuf,YWBuf))\n",
        "          # print(\"WInSortDicShape=\",w.shape)\n",
        "          # print(\"XWBuf=\",XWBuf)\n",
        "          # print(\"YWBuf=\",YWBuf)\n",
        "          for x in range(XWBuf):\n",
        "            for y in range(YWBuf):\n",
        "              str=x,y\n",
        "              # print(\"str\",str)\n",
        "              # print(\"w[x,y]\",w[x,y])\n",
        "              DicWeight[str]=w[x,y]\n",
        "              \n",
        "          #sort dic of weight baes on value:dic(key,value)\n",
        "          DicWSort=dict(sorted(DicWeight.items(), key=lambda item: item[1]))\n",
        "          # print(\"DicWSort=\",DicWSort)\n",
        "          \n",
        "          for x in range(XWBuf*YWBuf):\n",
        "            ListKeyWeight.append(list(DicWSort.keys())[x])\n",
        "            \n",
        "          # print(\"ListKeyWeight=\",ListKeyWeight)\n",
        "            \n",
        "        #/////////////////////////////////////////////////////////////////////////////////////////////////////\n",
        "        \n",
        "        #function for doing the functional of PE in skippy based on BISC & Uo/Down counter & Down counter\n",
        "        def Mul(InputBuffer,WeightBuffer):\n",
        "          OutputArray=np.array([])\n",
        "          # print(\"WeightBufferBeforReshape=\",WeightBuffer)\n",
        "          WeightBuffer=np.reshape(WeightBuffer,(XWBuf,YWBuf))\n",
        "          # print(\"WeightBufferAfterReshape=\",WeightBuffer)\n",
        "          \n",
        "          WeightBuffer1D=DetectTheMidValueOfRange(WeightBuffer)\n",
        "\n",
        "          # print(\"InputBuffershapeBefor=\",InputBuffer.shape)\n",
        "          InputBuffer=np.reshape(InputBuffer,(XInputBuf,YInputBuf))\n",
        "          # print(\"InputBuffershapeAfter=\",InputBuffer.shape)\n",
        "\n",
        "          #reshape WeightSortArray to 1-D\n",
        "          WeightBuffer1D=WeightBuffer.reshape(-1)\n",
        "          # print(\"WeightBuffer1D=\",WeightBuffer1D)\n",
        "          DifferentialW=GetDefferentialWArray(WeightBuffer1D)\n",
        "          \n",
        "          ClockNum=0\n",
        "          for i in range(len(DifferentialW)):\n",
        "            ClockNum=ClockNum+abs(DifferentialW[i])\n",
        "            \n",
        "          ClockNum*=((XInputBuf-XWBuf)+1)*((YInputBuf-YWBuf)+1)\n",
        "          # print(\"ClockNum=\",ClockNum)\n",
        "          \n",
        "          SortDicIndexWeight(WeightBuffer)\n",
        "          \n",
        "          for x in range((XInputBuf-XWBuf)+1):\n",
        "            for y in range((YInputBuf-YWBuf)+1):\n",
        "              \n",
        "              SelectIn=InputBuffer[x:XWBuf+x ,y:YWBuf+y]\n",
        "              # print(\"SelectInShape=\",SelectIn.shape)\n",
        "              # print(\"SelectIn=\",SelectIn)\n",
        "              \n",
        "              SumOut=0\n",
        "              \n",
        "              for a in range(XWBuf):\n",
        "                for b in range(YWBuf):\n",
        "                  LenDiffW= len(DifferentialW)\n",
        "                  SumList=[]\n",
        "                  \n",
        "                  for s in range(LenDiffW):\n",
        "                    SumList.append(0)\n",
        "\n",
        "                  X=SelectIn[a,b]\n",
        "                  XBinary=DecimalToBinary(X,XBit)\n",
        "                    \n",
        "                  SC=BISC(XBinary)\n",
        "                  andisY=0\n",
        "                    \n",
        "                  # print(\"LenDiffW\",LenDiffW)\n",
        "                  for z in range(LenDiffW):\n",
        "                    andisSC=0\n",
        "                    # print(\"z\",z)\n",
        "                      \n",
        "                    ValWInDiff=DifferentialW[z]\n",
        "                    #print(type(ValWInDiff))\n",
        "                      \n",
        "                    if ValWInDiff == 0:\n",
        "                      if z==0:\n",
        "                        SumList[andisY]=0\n",
        "                      else:\n",
        "                        SumList[andisY]=SumList[andisY-1]\n",
        "                      andisY+=1\n",
        "                      continue\t\t\t\t\t\t\n",
        "                        \n",
        "                    #instantiating the variable of sign holder \n",
        "                    #if sign=0, number is negative & sign=1, number is positive\n",
        "                      \n",
        "                    if ValWInDiff<0:\n",
        "                      sign=0\n",
        "                      ValWInDiff=abs(ValWInDiff)\n",
        "                    else:\n",
        "                      sign=1\n",
        "                        \n",
        "                    sum=0\n",
        "                    while ValWInDiff>0:\n",
        "                        \n",
        "                      OutUDCounter=UpDownCounter(ValWInDiff,SC[(len(SC)-1)-andisSC],sign)\n",
        "                      andisSC+=1\n",
        "                      ValWInDiff=DownCounter(ValWInDiff)\n",
        "                      sum=sum+OutUDCounter\n",
        "                        \n",
        "                        \n",
        "                    if z==0:\n",
        "                      SumList[andisY]=sum\n",
        "                    else:\n",
        "                      SumList[andisY]=SumList[andisY-1]+sum\n",
        "                    andisY+=1\n",
        "\n",
        "                  # print(\"SumList=\",SumList)\n",
        "                    \n",
        "                  Index=ListKeyWeight.index((a,b))\n",
        "                  val=SumList[Index]\n",
        "                  # print(\"ValIndex=\",val)\t\n",
        "                  SumOut=SumOut+val\n",
        "                  if SumOut >= (2**XBit):\n",
        "                    SumOut=2**XBit\n",
        "                    break\n",
        "                  if SumOut <= -(2**XBit):\n",
        "                    SumOut=-(2**XBit)\n",
        "                    break\n",
        "              # print(\"SumOut=\",SumOut)\n",
        "                \n",
        "              #two lines for compute the last result baesd on stochastic(divide on 2**XBit)\n",
        "              SumOut=SumOut/2**XBit\n",
        "              # print(\"SumOut=\",SumOut)\t\n",
        "                \n",
        "              OutputArray=np.append(OutputArray,SumOut)\n",
        "                \n",
        "          # print(\"OutputArray=\",OutputArray)\n",
        "          NewOutputArray=OutputArray.reshape((XInputBuf-XWBuf)+1,(YInputBuf-YWBuf)+1)\n",
        "          # print(\"NewOutputArray=\",NewOutputArray)\n",
        "          # print(\"NewOutputArrayShape=\",NewOutputArray.shape)\n",
        "          return NewOutputArray\n",
        "\n",
        "\n",
        "#////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "        self.inputs = np.zeros((C, W, H))\n",
        "        # print(\"self.inputsConv=\",self.inputs)\n",
        "\n",
        "        for c in range(inputs.shape[0]):\n",
        "            self.inputs[c,:,:] = self.zero_padding(inputs[c,:,:], self.p)\n",
        "        # print(\"OutshapeZero_padding=\",self.inputs.shape)\n",
        "\n",
        "        for c in range(C):\n",
        "          for w in range(W):\n",
        "            for h in range(H):\n",
        "              self.inputs[c,w,h]= int(self.inputs[c,w,h]*31)\n",
        "\n",
        "        self.inputs= self.inputs.astype(int)\n",
        "\n",
        "        # print(\"inputOfConvLayer=\",self.inputs)\n",
        "        # print(\"inputShapeOfConvLayer=\",self.inputs.shape)\n",
        "\n",
        "        #############  \n",
        "        WW =int((W - self.K)/self.s + 1)\n",
        "        # print(\"WW=\",WW)\n",
        "        ##########\n",
        "        HH = int((H - self.K)/self.s + 1)\n",
        "        # print(\"HH=\",HH)\n",
        "\n",
        "\n",
        "\n",
        "        feature_maps = np.zeros((self.F, WW, HH))\n",
        "        # print(\"feature_mapsShapeOfConvLayerzero=\",feature_maps.shape)\n",
        "\n",
        "        # print(\"FInConvInForward=\",self.F)\n",
        "\n",
        "\n",
        "        for f in range(self.F):\n",
        "          SumArrayF = np.zeros((WW, HH))\n",
        "          for c in range(self.C):\n",
        "            # print(\"f=\",f)\n",
        "            # print(\"c=\",c)\n",
        "\n",
        "            # print(\"inputssShape=\",self.inputs[c,:,:].shape)\n",
        "            # print(\"inputs=\",self.inputs[c,:,:])\n",
        "            # weights=np.reshape(self.weights[f,:,:,:],(XWBuf,YWBuf))\n",
        "            # print(\"weights=\",self.weights[f,c,:,:])\n",
        "            # print(\"OUTMulShape\",np.array(Mul(self.inputs[c,:,:],self.weights[f,c,:,:])).shape)\n",
        "            SumArrayF[:,:]=np.array(SumArrayF)+np.array(Mul(self.inputs[c,:,:],self.weights[f,c,:,:]))\n",
        "            # print(\"SumArrayFShape=\",SumArrayF[:,:].shape)\n",
        "            # print(\"SumArrayF=\",SumArrayF[:,:])\n",
        "\n",
        "\n",
        "          # print(\"SumArrayFShapeOUT=\",SumArrayF.shape)\n",
        "          # print(\"SumArrayF=\",SumArrayF)\n",
        "          \n",
        "          feature_maps[f,:,:]=SumArrayF[:,:]+self.bias[f]\n",
        "            \n",
        "        # print(\"feature_mapsShapeOfConvLayer=\",feature_maps.shape)\n",
        "        \n",
        "\n",
        "        return feature_maps\n",
        "    \n",
        "\n",
        "    def backward(self, output_error, learning_rate):\n",
        "        # print(\"output_errorInBackConvShape=\",output_error.shape)\n",
        "\n",
        "        C, W, H = self.inputs.shape\n",
        "        # print(\"inputsconvvvv.shape=\",self.inputs.shape)\n",
        "\n",
        "        WW =int((W - self.K)/self.s + 1)\n",
        "        # print(\"WW=\",WW)\n",
        "        ##########\n",
        "        HH = int((H - self.K)/self.s + 1)\n",
        "        # print(\"HH=\",HH)\n",
        "\n",
        "        self.weights=self.weights.astype(float)\n",
        "\n",
        "\n",
        "        dx = np.zeros(self.inputs.shape)\n",
        "        dw = np.zeros(self.weights.shape)\n",
        "        db = np.zeros(self.bias.shape)\n",
        "\n",
        "\n",
        "        F= output_error.shape[0]\n",
        "        # print(\"F=\",F,\"ForOutputErrorShapeInBackConv\")\n",
        "        output_error=np.reshape(output_error,(F,WW,HH))\n",
        "        \n",
        "        # print(\"output_errorInBackConvShape=\",output_error.shape)\n",
        "\n",
        "        for f in range(F):\n",
        "            for w in range(0, WW, self.s):\n",
        "                for h in range(0, HH, self.s):\n",
        "                    dw[f,:,:,:]+=output_error[f,w,h]*self.inputs[:,w:w+self.K,h:h+self.K]\n",
        "                    dx[:,w:w+self.K,h:h+self.K]+=output_error[f,w,h]*self.weights[f,:,:,:]\n",
        "\n",
        "        for f in range(F):\n",
        "            db[f] = np.sum(output_error[f, :, :])\n",
        "\n",
        "        self.weights -= learning_rate * dw\n",
        "        self.bias -= learning_rate * db\n",
        "        # print(\"conv's backward is done\")\n",
        "        return dx\n",
        "\n",
        "    def extract(self):\n",
        "        return {self.name+'.weights':self.weights, self.name+'.bias':self.bias}\n",
        "\n",
        "    def feed(self, weights, bias):\n",
        "        self.weights = weights\n",
        "        self.bias = bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhZYbVwxtd7c"
      },
      "outputs": [],
      "source": [
        "class Maxpooling2D:\n",
        "\n",
        "    def __init__(self, pool_size, stride):\n",
        "        self.pool = pool_size\n",
        "        self.s = stride\n",
        "        # print(\"pool_size(pooling layer)=\",self.pool)\n",
        "        # print(\"self.s(pooling layer)=\",self.s)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        C, W, H = inputs.shape\n",
        "        # print(\"InputsShape(pooling layer)=\",inputs.shape)\n",
        "        new_width =int((W - self.pool)/self.s + 1)\n",
        "        # print(\"new_width(pooling layer)=\",new_width)\n",
        "        new_height = int((H - self.pool)/self.s + 1)\n",
        "        # print(\"new_height(pooling layer)=\",new_height)\n",
        "        out = np.zeros((C, new_width, new_height))\n",
        "        for c in range(C):\n",
        "            for w in range(int(W/self.s)):\n",
        "                for h in range(int(H/self.s)):\n",
        "                    out[c, w, h] = np.max(self.inputs[c, w*self.s:w*self.s+self.pool, h*self.s:h*self.s+self.pool])\n",
        "        # print(\"pool's forward is done\")\n",
        "        return out\n",
        "\n",
        "    def backward(self,  output_error, learning_rate):\n",
        "        # print(\"output_errorInBackMax=\",output_error.shape)\n",
        "        C, W, H = self.inputs.shape\n",
        "        # print(\"C=\",C,\"W=\",W,\"H=\",H,\"ForOutputErrorShapeInBackMax\")\n",
        "        dx = np.zeros(self.inputs.shape)\n",
        "        \n",
        "        for c in range(C):\n",
        "            for w in range(0, W, self.pool):\n",
        "                for h in range(0, H, self.pool):\n",
        "                    # print(\"selectInput=\",self.inputs[c,w:w+self.pool,h:h+self.pool])\n",
        "                    # print(\"argmaxSelectInput=\",np.argmax(self.inputs[c,w:w+self.pool,h:h+self.pool]))\n",
        "                    st = np.argmax(self.inputs[c,w:w+self.pool,h:h+self.pool])\n",
        "                    # print(\"stShape=\",st.shape)\n",
        "                    (idx, idy) = np.unravel_index(st, (self.pool, self.pool))\n",
        "                    # print(\"idx=\",idx,\"idy=\",idy)\n",
        "                    dx[c, w+idx, h+idy] = output_error[c,int( w/self.pool), int(h/self.pool)]\n",
        "                    # print(\"dxshape=\",dx.shape)\n",
        "        # print(\"pool's backward is done\")\n",
        "        return dx\n",
        "\n",
        "    def extract(self):\n",
        "        return "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTrTMpTwtLXd"
      },
      "outputs": [],
      "source": [
        "class FCLayer:\n",
        "    def __init__(self, input_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        # print(\"input_size(FC layer)=\",self.input_size)\n",
        "        # print(\"output_size(FC layer)=\",self.output_size)\n",
        "        self.weights = np.random.randn(input_size, output_size) / np.sqrt(input_size + output_size)\n",
        "        self.bias = np.random.randn(1, output_size) / np.sqrt(input_size + output_size)\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        return np.dot(input, self.weights) + self.bias\n",
        "        # print(\"FC's forward is done\")\n",
        "\n",
        "    def backward(self, output_error, learning_rate):\n",
        "        # print(\"FCLayer's shape_output_error----In=\",output_error.shape)\n",
        "        input_error = np.dot(output_error, self.weights.T)\n",
        "        weights_error = np.dot(self.input.T, output_error)\n",
        "        # bias_error = output_error\n",
        "        \n",
        "        \n",
        "        self.weights -= learning_rate * weights_error\n",
        "        self.bias -= learning_rate * output_error\n",
        "        # print(\"FCLayer input_errorShape=\",input_error.shape)\n",
        "        # print(\"FC's backward is done\")\n",
        "        return input_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6nSYAB2sam3"
      },
      "outputs": [],
      "source": [
        "class ActivationLayer:\n",
        "    def __init__(self, activation, activation_prime):\n",
        "        self.activation = activation\n",
        "        self.activation_prime = activation_prime\n",
        "    \n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        return self.activation(input)\n",
        "        # print(\"Activation's forward is done\")\n",
        "    \n",
        "    def backward(self, output_error, learning_rate):\n",
        "        return output_error * self.activation_prime(self.input)\n",
        "        # print(\"Activation's backward is done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hl8LxP1lAEiN"
      },
      "outputs": [],
      "source": [
        "# bonus\n",
        "class FlattenLayer:\n",
        "    def __init__(self, input_shape):\n",
        "        self.input_shape = input_shape\n",
        "        # print(\"input_shape(Flatten layer)=\",self.input_shape)\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        return np.reshape(input, (1, -1))\n",
        "        # print(\"Flatten's forward is done\")\n",
        "    \n",
        "    def backward(self, output_error, learning_rate):\n",
        "        # print(\"Flatten's shape_output----In=\",output_error.shape)\n",
        "        # print(\"Flatten's shape_output\",(np.reshape(output_error, self.input_shape)).shape)\n",
        "        return np.reshape(output_error, self.input_shape)\n",
        "        # print(\"Flatten's backward is done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQeuIfkK3vyl"
      },
      "outputs": [],
      "source": [
        "# bonus\n",
        "class SoftmaxLayer:\n",
        "    def __init__(self, input_size):\n",
        "        self.input_size = input_size\n",
        "        # print(\"input_size(Softmax layer)=\",self.input_size)\n",
        "    \n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        tmp = np.exp(input)\n",
        "        self.output = tmp / np.sum(tmp)\n",
        "        # print(\"Softmax's forward is done\")\n",
        "        return self.output\n",
        "    \n",
        "    def backward(self, output_error, learning_rate):\n",
        "        # print(\"SoftmaxLayer's shape_output----In=\",output_error.shape)\n",
        "        input_error = np.zeros(output_error.shape)\n",
        "        out = np.tile(self.output.T, self.input_size)\n",
        "        # print(\"Softmax's backward is done\")\n",
        "        return self.output * np.dot(output_error, np.identity(self.input_size) - out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuPbn70Wt8Q7"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_prime(x):\n",
        "    return np.exp(-x) / (1 + np.exp(-x))**2\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def tanh_prime(x):\n",
        "    return 1 - np.tanh(x)**2\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(x, 0)\n",
        "\n",
        "def relu_prime(x):\n",
        "    return np.array(x >= 0).astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXY7jkUzuqEk"
      },
      "outputs": [],
      "source": [
        "def mse(y_true, y_pred):\n",
        "    return np.mean(np.power(y_true - y_pred, 2))\n",
        "\n",
        "def mse_prime(y_true, y_pred):\n",
        "    return 2 * (y_pred - y_true) / y_pred.size\n",
        "\n",
        "def sse(y_true, y_pred):\n",
        "    return 0.5 * np.sum(np.power(y_true - y_pred, 2))\n",
        "\n",
        "def sse_prime(y_true, y_pred):\n",
        "    return y_pred - y_true"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "import sys\n",
        "import pickle\n",
        "import gzip\n",
        "f = gzip.open('mnist.pkl.gz', 'rb')\n",
        "if sys.version_info < (3,):\n",
        "    data = pickle.load(f)\n",
        "else:\n",
        "    data = pickle.load(f, encoding='bytes')\n",
        "f.close()\n",
        "import numpy as np\n",
        "(x_train, y_train), (x_test, y_test) = data\n",
        "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_train /= 255\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "x_train = x_train[0:2000]\n",
        "y_train = y_train[0:2000]\n",
        "\n",
        "x_test = x_test[0:200]\n",
        "y_test = y_test[0:200]\n",
        "x_test = x_test.astype('float32')\n",
        "x_test /= 255\n",
        "y_test = np_utils.to_categorical(y_test)"
      ],
      "metadata": {
        "id": "M6Dvl4tffgmQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "db7e1982-a4c8-48b4-f019-be2e77cacc24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-8b25ca0f665d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist.pkl.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/gzip.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mgz_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"write\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mnist.pkl.gz'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHQpwN8LpKiN"
      },
      "outputs": [],
      "source": [
        "# unlike the Medium article, I am not encapsulating this process in a separate class\n",
        "# I think it is nice just like this\n",
        "network = [\n",
        "    Convolution2D(1, 6, 5, 2, 1),\n",
        "    ActivationLayer(relu, relu_prime),\n",
        "    Maxpooling2D(2,2),\n",
        "    Convolution2D(6,16,5,0,1),\n",
        "    ActivationLayer(relu, relu_prime),\n",
        "    Maxpooling2D(2,2),\n",
        "    Convolution2D(16, 120,5,0,1),\n",
        "    FlattenLayer(120),\n",
        "    FCLayer(120, 84),\n",
        "    ActivationLayer(relu, relu_prime),\n",
        "    FCLayer(84, 10),\n",
        "    SoftmaxLayer(10)\n",
        "]\n",
        "\n",
        "epochs = 20\n",
        "learning_rate = 0.1\n",
        "\n",
        "# training\n",
        "for epoch in range(epochs):\n",
        "    error = 0\n",
        "    for x, y_true in zip(x_train, y_train):\n",
        "        # forward\n",
        "        # print(\"x=\",x)\n",
        "        # print(\"y_true=\",y_true)\n",
        "        # print(\"shapex=\",x.shape)\n",
        "        output = x.reshape((1,x.shape[0], x.shape[1]))\n",
        "        # print(\"xReshape=\",output)\n",
        "        # print(\"shapexReshape=\",output.shape)\n",
        "        for layer in network:\n",
        "          output = layer.forward(output)\n",
        "          # print(\"forward\",layer, \"finish\")\n",
        "          # input(\"plz enter the word\")\n",
        "        \n",
        "        # print(\"forward epoch\",epoch,\"finish\")\n",
        "        # error (display purpose only)\n",
        "        error += mse(y_true, output)\n",
        "\n",
        "        # backward\n",
        "        output_error = mse_prime(y_true, output)\n",
        "\n",
        "        for layer in reversed(network):\n",
        "            output_error = layer.backward(output_error, learning_rate)\n",
        "            # print(\"backward\",layer,\"finish\")\n",
        "            # input(\"plz enter the word\")\n",
        "\n",
        "\n",
        "            # print(\"output_errorShape=\",output_error.shape)\n",
        "            \n",
        "\n",
        "        # print(\"backward epoch\",epoch,\"finish\")\n",
        "        # input(\"plz enter the word\")\n",
        "\n",
        "    \n",
        "    error /= len(x_train)\n",
        "    print('%d/%d, error=%f' % (epoch + 1, epochs, error))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrMLx3eGv3jk"
      },
      "outputs": [],
      "source": [
        "def predict(network, input):\n",
        "    prediction=True\n",
        "    \n",
        "    x=input.reshape(1,input.shape[0],input.shape[1])\n",
        "    # print(\"shapereshape\",(input.reshape(1,input.shape[0],input.shape[1])).shape)\n",
        "    output = x\n",
        "    # print(\"inputShape\",input.shape)\n",
        "\n",
        "    # print(\"Prediction In Test=\",prediction)\n",
        "\n",
        "    for layer in network:\n",
        "      # print(\"layer.name\",layer) \n",
        "      if layer == network[0]:\n",
        "        output = layer.forwardStochastic(output)\n",
        "      elif layer == network[3]:\n",
        "        output = layer.forwardStochastic(output)\n",
        "      elif layer == network[6]:\n",
        "        output = layer.forwardStochastic(output)\n",
        "      else:\n",
        "        output = layer.forward(output)\n",
        "        # print(\"outputShape\",output.shape)\n",
        "    return output\n",
        "\n",
        "ratio = sum([np.argmax(y) == np.argmax(predict(network, x)) for x, y in zip(x_test, y_test)]) / len(x_test)\n",
        "error = sum([mse(y, predict(network, x)) for x, y in zip(x_test, y_test)]) / len(x_test)\n",
        "print('ratio: %.2f' % ratio)\n",
        "print('mse: %.4f' % error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERV5_QinvwXY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "samples = 10\n",
        "for test, true in zip(x_test[:samples], y_test[:samples]):\n",
        "    image = np.reshape(test, (28, 28))\n",
        "    plt.imshow(image, cmap='binary')\n",
        "    plt.show()\n",
        "    pred = predict(network, test)[0]\n",
        "    idx = np.argmax(pred)\n",
        "    idx_true = np.argmax(true)\n",
        "    print('pred: %s, prob: %.2f, true: %d' % (idx, pred[idx], idx_true))"
      ]
    }
  ]
}